<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Support Vector Machine | YYYOUC</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="IntroductionWhen it comes to classification methods, there are two categories. The first category is to construct a discriminant function for each class, and then classify each sample to the class wit">
<meta property="og:type" content="article">
<meta property="og:title" content="Support Vector Machine">
<meta property="og:url" content="http://yoursite.com/2015/07/07/Support Vector Machine/index.html">
<meta property="og:site_name" content="YYYOUC">
<meta property="og:description" content="IntroductionWhen it comes to classification methods, there are two categories. The first category is to construct a discriminant function for each class, and then classify each sample to the class wit">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Support Vector Machine">
<meta name="twitter:description" content="IntroductionWhen it comes to classification methods, there are two categories. The first category is to construct a discriminant function for each class, and then classify each sample to the class wit">
  
    <link rel="alternative" href="/atom.xml" title="YYYOUC" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">YYYOUC</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="q" value="site:http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Support Vector Machine" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/07/07/Support Vector Machine/" class="article-date">
  <time datetime="2015-07-08T04:09:39.000Z" itemprop="datePublished">2015-07-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Support Vector Machine
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Introduction">Introduction</h2><p>When it comes to classification methods, there are two categories. The first category is to construct a <strong>discriminant function</strong> for each class, and then classify each sample to the class with the largest value for its discriminant function, such as logistic regression method. The second method is to construct a <strong>separating hyperplane</strong>, such as perceptron method and SVM.</p>
<h2 id="Objective_function">Objective function</h2><p>SVM is to find an optimal separating hyperplane among different classes such that the <strong>margin</strong> is maximized, where margin is the smallest distance between the separating plane and any of the samples. </p>
<p>The objective function is as follows,<br>$$\max_{w,b} margin(w, b) \\<br>s.t. y_i(w^Tx_i+b)&gt;0$$<br>where $margin(w,b)=\min_{i=1,2,..,N}distance(x_i,w,b)$, and $distance(x_i, w, b)=\frac{|w^Tx_i+b|}{||w||}=\frac{y_i(w^Tx_i+b)}{||w||}$. The constraint means that we are only interested in the hyperplane for which all samples are correctly classified.</p>
<p>Due to the linearity of the hyperplane, there exists many representations for the same hyperplane, for example, $(kw)^Tx+kb=0$. To avoid such cases, we scale $w$ and $b$ such that $\min_{i=1,2,..,N} y_i(w^Tx_i+b)=1$. Thus, $margin(w,b)=\frac{1}{||w||}$. Thus, the objective function is as follows.<br>$$ \max_{w,b}\frac{1}{||w||} \\<br>s.t. y_i(w^Tx_i+b)\geq1 $$<br>It is equivalent to the following:<br>$$ \min_{w,b}\frac{1}{2}w^Tw \\<br>s.t. y_i(w^Tx_i+b)\geq1 $$</p>
<h2 id="Optimization_algorithm">Optimization algorithm</h2><p>There are two methods to solve this objective function. The first method is to solve the primal problem directly. The second method is to solve the dual problem.</p>
<h3 id="1-_Primal_problem">1. Primal problem</h3><p>This problem is a quadratic programming (QP) problem. It can be solved directly by many optimization tools. The general form of the QP problem is as follows.<br>$$\min_{u} \frac{1}{2}u^TQu+p^Tu \\<br>s.t.a_i^Tu\geq c_i , i=1,…,m<br>$$<br>The objective function of SVM can be represented as such form, where $u=\left[<br>  \begin{array}{c}<br>    b\\ w<br>  \end{array}<br>\right] $, $Q=\left[<br>  \begin{array}{cc}<br>    0 &amp; 0_d^T \\<br>    0_d &amp; I_d<br>  \end{array}<br>\right] $, $p=0_{d+1}$, $a_i^T=y_i[1,  x_i^T]$,$c_i=1$. For this method, the number of the variables is $d$ (the number of features), and the number of the constraints is $N$ (the number of samples). If $d$ is very large, especially for the kernel SVM, the computation will also be very large. How to address this problem? We can solve the dual problem rather than the primal problem.</p>
<h3 id="2-_Dual_problem">2. Dual problem</h3><h4 id="2-1_Duality">2.1 Duality</h4><p>At first, we will talk about some basic knowledge about the dual problem. We consider a standard optimization problem:<br>$$<br>\min f_0(x)  \\<br>s.t. f_i(x) \leq 0, i=1,…,m \\<br>h_i(x) = 0, i=1,…,p<br>$$<br>This is a constrained optimization problem. Ususally it is more difficult to solve than the unconstrained optimization problem. Can we transform it to an unconstrained one? Of course, we define a Lagrangian function as follows:<br>$$L(x,\lambda, v)=f_0(x)+\sum_{i=1}^m\lambda_i f_i(x)+\sum_{i=1}^pv_ih_i(x)$$<br>where $\lambda_i$ and $v_i$ is the Lagrangian multiplier. Note that we put the constraint into the objective function so that it becomes an uncontrained problem. However, are they equivalent?<br>Consider the following function:<br>\begin{equation}<br>\theta_p(x)=\max_{\lambda_i,v_i: \lambda_i\geq 0} L(x, \lambda, v)<br>\end{equation}<br>If some constraint are violated, such as $f_i(x)&gt;0$ or $h_i(x)\neq0$, we can adjust $\lambda_i$ and $v_i$ such that $\theta_p(x)$ approaches to infinity. If all the constraints are satisifed, it is easy to know that $\lambda_i$ should be equal to 0, and then $\theta_p(x)$ is equal to $f_0(x)$ exactly. Thus, we can minimize $\theta_p(x)$ to enforce the constraint to be satisfied, that is<br>\begin{equation}<br>\min_{x}\theta_p(x)=\min_{x} \max_{\lambda_i,v_i: \lambda_i\geq 0} L(x, \lambda, v)<br>\end{equation}<br>then it will be equivalent the standard form. This is the primal problem, in the following we will derive the dual problem. Note that for any $\lambda’$ and $v’$, we have $$\min_{x} \max_{\lambda_i,v_i: \lambda_i\geq 0} L(x, \lambda, v) \geq \min_{x} L(x, \lambda’, v’)$$ (because max $\geq$ any), and then $$\min_{x} \max_{\lambda_i,v_i: \lambda_i\geq 0} L(x, \lambda, v) \geq \max_{\lambda_i’,v_i’: \lambda_i’\geq 0}\min_{x} L(x, \lambda’, v’)$$ (because best is one of any).<br>The right side is the dual problem, and $\min_{x} L(x, \lambda, v)$ is the dual function. Note that the dual problem gives a lower bound to the primal problem. </p>
<p>When the solution $x^{<em>}$, $\lambda^{</em>}$ and $v^{*}$ satisfy the KKT conditions, they are the solution of both primal and dual problems.</p>
<h4 id="2-2_Dual_SVM">2.2 Dual SVM</h4><p>Based on the above foundation, the dual SVM is as follows<br>$$\max_{\alpha_i\geq 0}{\min_{b,w}\frac{1}{2}w^Tw+\sum_{i=1}^{N}\alpha_i(1-y_i(w^Tx_i+b))}$$</p>
<p>At first, we solve the inner problem<br> $$\min_{b,w}\frac{1}{2}w^Tw+\sum_{i=1}^{N}\alpha_i(1-y_i(w^Tx_i+b))$$<br> This is an unconstrained problem. It is easy to solve by setting the direvative with respect to $w$ and $b$ as zero. We can get<br> $$<br> \sum_{i=1}^{N}\alpha_iy_i=0 \\<br> \sum_{i=1}^{N}\alpha_iy_ix_i=w<br> $$<br> Then,<br>$$<br>\frac{1}{2}w^Tw+\sum_{i=1}^{N}\alpha_i(1-y_i(w^Tx_i+b)) \\<br>=\frac{1}{2}w^T\sum_{i=1}^{N}\alpha_iy_ix_i+\sum_{i=1}^{N}\alpha_i-w^T\sum_{i=1}^N\alpha_iy_ix_i-b\sum_{i=1}^N\alpha_iy_i \\<br>=\sum_{i=1}^{N}\alpha_i-\frac{1}{2}w^T\sum_{i=1}^{N}\alpha_iy_ix_i \\<br>= \sum_{i=1}^{N}\alpha_i-\frac{1}{2}(\sum_{i=1}^{N}\alpha_iy_ix_i)^T\sum_{i=1}^{N}\alpha_iy_ix_i \\<br>= \sum_{i=1}^{N}\alpha_i-\frac{1}{2}\sum_{i,j=1}^{N}\alpha_i\alpha_jy_iy_jx_i^Tx_j<br>$$<br>Now we have the dual problem as follows.<br>$$<br>\min \frac{1}{2}\sum_{i=1}^{N}\sum_{j=1}^{N}\alpha_i\alpha_jy_iy_jx_i^Tx_j-\sum_{i=1}^{N}\alpha_i \\<br>s.t. \alpha_i \geq 0, i=1,…,N \\<br> \sum_{i=1}^{N}\alpha_iy_i=0<br>$$<br>This is a QP with $N$ variables and $N+1$ constraints. Therefore, it can be easily solved by optimization tools. Note that when we solve this QP, the matrix $Q$ consists of $q_{ij}=y_iy_jx_i^Tx_j$ usually is dense. Thus, it needs large storage.</p>
<p>After we got the solution of the dual problem, how can we get the primal solution $w$ and $b$? Note that $w=\sum_{i=1}^{N}\alpha_iy_ix_i$. Whats more, according to the KKT dual complementary conditions,$\alpha_i(1-y_i(w^Tx_i+b))=0$, if $\alpha_i&gt;0$, $1-y_i(w^Tx_i+b)=0$, that is $b=y_i-w^Tx_i$. Note that $\alpha_i&gt;0$ means $y_i(w^Tx_i+b)=1$, thus this point locates on the boundary. Such points are called <strong>support vector</strong>. </p>
<p>After obtainning the optimal $w$ and $b$ from the trainning data, we can classify the test data by the following formula.<br>$$<br>w^Tx+b=(\sum_{i=1}^N\alpha_iy_ix_i)^Tx+b=\sum_{i=1}^N\alpha_iy_i x_i^Tx+b<br>$$<br>Note that we only need to calculate the inner product between the testing data and the support vector (corresponds to $\alpha_i&gt;0$) rather than the whole training data, thus it is efficient.</p>
<h2 id="Soft-Margin_SVM">Soft-Margin SVM</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/07/07/Support Vector Machine/" data-id="cicclujql0006wsffpd5o4vlj" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/07/07/Support Vector Machine/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2015/07/18/Bayesian-Decision-Theory/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Bayesian Decision Theory
        
      </div>
    </a>
  
  
    <a href="/2015/05/17/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hello World</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
	<div id="disqus_thread"></div>
	<script type="text/javascript">
		/* * * CONFIGURATION VARIABLES * * */
		var disqus_shortname = 'yyyoucgithubio';
		
		/* * * DON'T EDIT BELOW THIS LINE * * */
		(function() {
			var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
			dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
			(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
		})();
	</script>
	<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</section>
</section>
        
          <aside id="sidebar">
  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/">Hexo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a><span class="tag-list-count">3</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a><a href="/tags/Machine-Learning/" style="font-size: 20px;">Machine Learning</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/07/">July 2015</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">May 2015</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2015/07/20/Density-Estimation/">Density Estimation</a>
          </li>
        
          <li>
            <a href="/2015/07/18/Bayesian-Decision-Theory/">Bayesian Decision Theory</a>
          </li>
        
          <li>
            <a href="/2015/07/07/Support Vector Machine/">Support Vector Machine</a>
          </li>
        
          <li>
            <a href="/2015/05/17/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
		
<section id="comment">	
	<div id="disqus_thread"></div>
	<script type="text/javascript">
		/* * * CONFIGURATION VARIABLES * * */
		var disqus_shortname = 'yyyouc';
		
		/* * * DON'T EDIT BELOW THIS LINE * * */
		(function() {
			var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
			dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
			(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
		})();
	</script>
	<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>
	
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 YYY OUC<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    
<script>
  var disqus_shortname = 'yyyouc';
  
  var disqus_url = 'http://yoursite.com/2015/07/07/Support Vector Machine/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>


<script type="text/x-mathjax-config"> 
MathJax.Hub.Config({ 
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} 
}); 
</script>
<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	


<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>