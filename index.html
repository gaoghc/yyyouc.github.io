<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>YYYOUC</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="YYYOUC">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="YYYOUC">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="YYYOUC">
<meta name="twitter:description">
  
    <link rel="alternative" href="/atom.xml" title="YYYOUC" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">YYYOUC</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="q" value="site:http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Accelerated-Gradient-Method" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/08/14/Accelerated-Gradient-Method/" class="article-date">
  <time datetime="2015-08-14T19:55:55.000Z" itemprop="datePublished">2015-08-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/14/Accelerated-Gradient-Method/">Accelerated Gradient Method</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-_Introduction">1. Introduction</h2><p>We have talked about three gradient-based method (or first order method) in the previous work, that is <strong>gradient descent method</strong>, <strong>subgradient method</strong> and <strong>proximal gradient method</strong>. Their convergence rate is $O(1/k)$, $O(1/\sqrt(k)$ and $O(1/k)$ respectively. Today we will talk about the accelerated gradient method whose convergence rate is $O(1/k^2)$.</p>
<p>In the following, we will talk about Nesterov’s three accelerated methods corresponding his three papers:</p>
<ul>
<li>Y. Nesterov (1983), A method for solving a convex programming problem with convergence rate $O(1/k^2)$</li>
<li>Y. Nesterov (1988) On an approach to the construction of optimal methods of minimization of smooth convex functions</li>
<li>Y. Nesterov (2005), Smooth minimization of non-smooth functions<br>In addition, we will talk about <strong>FISTA</strong> method</li>
</ul>
<p>There is an assumption about $f$:</p>
<ul>
<li>$f$ is a convex function with an $L$-Lipshitz continuous derivative.</li>
</ul>
<h2 id="2-_Nesterov’s_First_Method_(1983)">2. Nesterov’s First Method (1983)</h2><p>Choose $x<em>0$ and set $x_0=x\</em>{-1}$. For all $k\geq 1$, repeat the steps</p>
<ul>
<li>$y = x_{k-1} + \frac{k-2}{k+1}(x_{k-1} - x_{k-2})$</li>
<li>$x_k = y-t_k\nabla f(y)$</li>
</ul>
<p>where $t_k$ is the step length. </p>
<p>Note that</p>
<ul>
<li>First iteration (k=1) is a gradient step at $y=x_0$</li>
<li>Next iterations are the gradient steps at extrapolated points $y$</li>
<li>$\frac{k-2}{k+1}(x_{k-1} - x_{k-2})$ can be viewed as the <strong>momentum term</strong>.</li>
</ul>
<p>Define $\theta_k = \frac{2}{k+1}$ and introduce an intermediate variable $v_k$. We can reformulate the above iterative steps as follows:<br>Choose $x_0=v_0$, for all $k\geq 1$, repeat the steps:</p>
<ul>
<li>$y = (1-\theta_k) x_{k-1} + \theta_k v_{k-1}$</li>
<li>$x_{k} = y - t_k\nabla f(y)$</li>
<li>$v_{k} = x_{k-1}+\frac{1}{\theta_k}(x_k-x_{k-1})$</li>
</ul>
<p>This expression makes convergence analysis easier.</p>
<h2 id="3-_Nesterov’s_Second_Method_(1988)">3. Nesterov’s Second Method (1988)</h2><p>Choose $x_0=v_0$, for all $k\geq 1$, repeat the steps</p>
<ul>
<li>$y = (1-\theta_k)x_{k-1}+\theta_k v_{k-1}$</li>
<li>$v_k =v_{k-1} - \frac{t_k}{\theta_k}\nabla g(y)$</li>
<li>$x_k = (1-\theta_k)x_{k-1} + \theta_k v_{k}$</li>
</ul>
<p>where $t_k$ is the step size and $\theta_k=\frac{2}{k+1}$</p>
<h2 id="4-_Nesterov’s_Third_Method_(2005)">4. Nesterov’s Third Method (2005)</h2><p>abc</p>
<h2 id="5-_Another_Formulation_(Beck_and_Teboulle_2009)">5. Another Formulation (Beck and Teboulle 2009)</h2><p>The general iterative step of the first method is as follows:<br>Choose $x_1$, set $y_1=x_1$, $\theta_1=1$, repeates:</p>
<ul>
<li>$x_{k+1}=y_{k} - t_k \nabla f(y_{k})$</li>
<li>$\theta_{k+1} = \frac{1+\sqrt{1+4\theta_{k}^2}}{2}$</li>
<li>$y_{k+1} = x_{k+1}+\frac{\theta_{k} - 1}{\theta_{k+1}}(x_{k+1}-x_{k})$</li>
</ul>
<p>where $t_k$ is the step size. Note that the three properties of $\theta_{k}$:</p>
<ul>
<li>$\theta_{k}$ is positive and increasing</li>
<li>$\theta_{k+1} \geq \theta_{k} + 1/2$</li>
<li>$\lim_{t-&gt;inf}\frac{\theta_{k} - 1}{\theta_{k+1}}=1$ </li>
</ul>
<h2 id="6-_Convergence_Rate">6. Convergence Rate</h2><p>If $f$ is a convex function with an $L$-Lipshitz continuous derivative, then the above method satisfies the following:</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/08/14/Accelerated-Gradient-Method/" data-id="cidcgcnxt0000f4ffc03xblti" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/08/14/Accelerated-Gradient-Method/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Optimization-Method/">Optimization Method</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Proximal-Gradient-Method" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/08/11/Proximal-Gradient-Method/" class="article-date">
  <time datetime="2015-08-12T01:22:29.000Z" itemprop="datePublished">2015-08-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/11/Proximal-Gradient-Method/">Proximal Gradient Method</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-_Introduction">1. Introduction</h2><p>The proximal algorithm is widely used recently. In this work, we will talk about some basic knowldege about the proximal algorithm and some concrete proximal methods.</p>
<p>Much like Newton’s method is a standard tool for solving unconstrained smooth minimization problems of modest size, proximal algorithms can be viewed as an analogous tool for <strong>nonsmooth, constrained, large-scale, or distributed</strong> versions of these problems.</p>
<p>In fact, the proximal algorithm is to solve the <strong>upper bound</strong> of the original problem to get the solution. We will talk about it in those concrete proximal algorithms.</p>
<h2 id="2-_Proximal_Mapping">2. Proximal Mapping</h2><p>In proximal algorithm, the base operation is evaluating the <strong>proximal operator</strong> of a function, which involves solving a small convex optimization problem. These subproblems can be solved with standard methods. More important, they often have closed-form solutions or can be solved very quickly with simple specialized methods.</p>
<h3 id="2-1_Definition">2.1 Definition</h3><p>The <strong>proximal operator</strong> $prox_f$ of function $f$ is defined as:<br>$$<br>prox_f(x) = \arg\min_{u}(f(u)+\frac{1}{2}||u-x||_2^2)<br>$$<br>If $f$ is closed and convex, $prox_f(x)$ <strong>exists</strong> and is <strong>unique</strong> for all $x$. Because the second derivative of the righthand side is $$\nabla^2 f(u) + I\geq I$$, then it is a strongly convex function. Therefore, it has unique optimal point.</p>
<p>In machine learning field, we often encounter the proximal operator of the scaled function $\lambda f$ as follows.<br>$$<br>prox_{\lambda f}(x) = \arg\min_{u}(f(u)+\frac{1}{2\lambda}||u-x||_2^2)<br>$$</p>
<h3 id="2-2_Examples">2.2 Examples</h3><p>(1). $f(x)=0$: $prox_f(x) = x$ </p>
<p>(2). $f(x)=I_C(x)$ (indictor function of C): $prox_h$ is the projection on C. $prox_h(x)=\arg\min_{u\in C}||u-x||_2^2=P_C(x)$</p>
<p>(3). $f(x)=||x||_1$: $prox_h$ is the ‘soft-threshold’ (shrinkage) operation<br>$$ prox_h(x)_i=\left\{<br>\begin{array}{lcl}<br>x_i-1       &amp;      &amp; {x_i\geq 1}\\<br>0     &amp;      &amp; {|x_i| \leq 1}\\<br>x_i+1     &amp;      &amp; {x_i\leq -1}\\<br>\end{array} \right. $$</p>
<h2 id="3-_Proximal_Gradient_Method">3. Proximal Gradient Method</h2><p>In machine learning application, we often encounter the following objective function:<br>$$<br>\min f(x)+\lambda h(x)<br>$$ where $f(x)$ is convex and differentiable, usually it is a loss function. $h(x)$ is convex with inexpensive prox-perator,usually it is a regularizer. For example, the hinge regression problem<br>$$\min_{W} ||Y-W^TX||_F^2+||W||_1$$ where $f(W)=||Y-W^TX||_F^2$, $h(W) = ||W||_1$.</p>
<h3 id="3-1_Key_Idea">3.1 Key Idea</h3><p><strong>The key idea of the proximal gradient method is to minimize the upper bound of the origial objective</strong>.<br>The general fomulation of proximal gradient method is as follows.<br>$$<br>x_{t+1} = prox_{s_{k+1}h}(x_{t}-s_{k+1}\nabla f(x_t))<br>$$where $s_{k+1}&gt;0$ is the step size. </p>
<p>However, what’s the meaning of this iterative step? Assume $f(x)$ is Lipschitz continous, then<br>$$f(x)\leq f(x_t)+ \nabla f(x_t)^T(x-x_t) + \frac{L}{2}||x-x_t||_2^2 \triangleq g(x)$$ The upper bound $g(x)=\frac{L}{2}||x-a||_2^2+c$ where $a=x_t-\frac{1}{L}\nabla f(x_t)$ and $c=f(x_t)-\frac{1}{2L}||\nabla f(x_t)||_2^2$. Therefore, using the upper bound $g(x)$, we can solve $\min f(x)+\lambda h(x)$  by<br>$$<br>\min \frac{L}{2}||x-a||_2^2 +\lambda h(x)<br>$$where $a=x_t-\frac{1}{L}\nabla f(x_t)$. Usually, the new objective is easier to solve than the original one.<br>Therefore,<br>$$<br>x_{t+1}=\arg\min_{x}(\frac{L}{2}||x-a||_2^2 +\lambda h(x)) \<br>= \arg\min_{x}(||x-a||_2^2 +\frac{2\lambda}{L} h(x)) \<br>= prox_{\frac{2\lambda}{L} h}(a)<br>= prox_{\frac{2\lambda}{L} h}(x_t-\frac{1}{L}\nabla f(x_t))<br>$$<br>All in all, we can conclude that the proximal gradient method is to solve the upper bound of the original problem.</p>
<h3 id="3-2_Convergence">3.2 Convergence</h3><p>The objective function is as follows:<br>$$<br>\min_{x} f(x)=g(x)+h(x)<br>$$ The iterative step of proximal gradient method is<br>$$<br>x_{k} = prox_{t_kh}(x_{k-1}-t\nabla g(x_{k-1}))<br>$$ We can reformulate the iterative step as follows:<br>$$x_{k} = prox_{t_kh}(x_{k-1}-t\nabla g(x_{k-1})) \<br>=x_{k-1}-tG_t(x_{k-1})<br>$$ where $G_t(x_{k-1}) = \frac{1}{t}(x_{k-1}-prox_{th}(x_{k-1}-t\nabla g(x_{k-1})))$. We can view $G_t(x)$ as the <strong>‘step’</strong> in the proximal gradient update.</p>
<ul>
<li>Note that $G_t(x)$ is not the gradient or subgradient of $f=g+h$</li>
<li>From the subgradient definition of prox-operator, we have<br>$$<br>G_t(x) \in \nabla g(x) + \partial h(x-tG_t(x))<br>$$Because $u=prox_h(x)$ means $\partial h(u) + u -x = 0$, then $x-u\in \partial h(u)$</li>
</ul>
<h4 id="3-2-1_Assumptions">3.2.1 Assumptions</h4><ul>
<li>$g(x)$ is convex, and $\nabla g(x)$ is Lipschitz continous with constant L:<br>$$||\nabla g(x) - \nabla g(y)||_2\leq ||x-y||_2$$</li>
<li>$h(x)$ is closed and convex, then $porx_{th}$ is well defined.</li>
</ul>
<h4 id="3-2-2_Convergence_of_fixed_step_length">3.2.2 Convergence of fixed step length</h4><p>Due to the convexity and the Lipschitz continous gradient of $g$, we have<br>$$<br>g(y)\leq g(x)+\nabla g(x)^T(y-x) + \frac{L}{2}||y-x||_2^2<br>$$ Let $y=x-tG_t(x)$, we have<br>$$<br>g(x-tG_t(x))\leq g(x) - t\nabla g(x)^TG_t(x)+\frac{t^2L}{2}||G_t(x)||_2^2<br>$$ If $0\leq t \leq 1/L$, then<br>$$<br>g(x-tG_t(x))\leq g(x) - t\nabla g(x)^TG_t(x)+\frac{t}{2}||G_t(x)||_2^2<br>$$<br>Then, for the entire objective function, we have the following inequality for all $z$<br>$$<br>f(x-tG_t(x))\leq f(z)+G_t(x)^T(x-z)-\frac{t}{2}||G_t(x)||_2^2<br>$$ Because<br>$$<br>f(x-tG_t(x))\leq g(x) - t\nabla g(x)^TG_t(x)+\frac{t}{2}||G_t(x)||_2^2 + h(x-tG_t(x)) \\<br>\leq g(z)+\nabla g(x)^T(x-z)-t\nabla g(x)^TG_t(x)+\frac{t}{2}||G_t(x)||_2^2 +h(z)+v^T(x-z-tG_t(x)) \\<br>= g(z) + h(z) + G_t(x)^T(x-z)-\frac{t}{2}||G_t(x)||_2^2<br>$$ where $v=G_t(x)-\nabla g(x) \in \partial h(x-tG_t(x))$.</p>
<p>Let $x_{k+1}=x_k-tG_t(x)$, $z=x_k$, we have<br>$$<br>f(x_{k+1})\leq f(x_{k}) - \frac{t}{2} ||G_t(x_k)||_2^2<br>$$<br>And if we let $z=x_{opt}$, we have<br>$$<br>f(x_{k+1})-f(x_{opt})\leq G_t(x_k)^T(x_k-x_{opt})-\frac{t}{2}||G_t(x_k)||_2^2 \\<br>= \frac{1}{2t}(||x_k-x_{opt}||_2^2-||x_k-x_{opt}-tG_t(x_k)||_2^2) \\<br>=\frac{1}{2t}(||x_k-x_{opt}||_2^2-||x_{k+1}-x_{opt}||_2^2)<br>$$<br>Therefore,<br>$$<br>\sum_{i=1}^k(f(x_i)-f_{opt}) \leq \frac{1}{2t}\sum_{i=1}^k(||x_{i-1}-x_{opt}||_2^2-||x_i-x_{opt}||_2^2) \\<br>= \frac{1}{2t} (||x_{0}-x_{opt}||_2^2-||x_k-x_{opt}||_2^2) \\<br>\leq \frac{1}{2t}||x_{0}-x_{opt}||_2^2<br>$$<br>Since $f$ is nonincreasing, we have<br>$$<br>f(x_k)-f_{opt} \leq \frac{1}{k}\sum_{i=1}^k(f(x_i)-f_{opt}) \leq \frac{1}{2kt}||x_0 - x_{opt}||_2^2<br>$$<br>Hence, it reaches $f(x_k)-f_{opt} \leq \epsilon$ after $O(1/\epsilon)$ iterations.</p>
<h4 id="3-2-3_Convergence_of_line_search_method">3.2.3 Convergence of line search method</h4><p>For the line search method, we have<br>$$<br>f(x_{k+1})-f(x_{opt})\leq \frac{1}{2t_i}(||x_k-x_{opt}||_2^2-||x_{k+1}-x_{opt}||_2^2) \<br>\leq \frac{1}{2t_{min}}(||x_k-x_{opt}||_2^2-||x_{k+1}-x_{opt}||_2^2)<br>$$ Then<br>$$<br>\sum_{i=1}^k(f(x_i)-f_{opt}) \leq \frac{1}{2t_{min}}||x_0 - x_{opt}||_2^2<br>$$<br>Similarly,$f$ is nonincreasing, we have<br>$$<br>f(x_k)-f_{opt}  \leq \frac{1}{2kt_{min}}||x_0 - x_{opt}||_2^2<br>$$<br>Hence, it also reaches $f(x_k)-f_{opt} \leq \epsilon$ after $O(1/\epsilon)$ iterations.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/08/11/Proximal-Gradient-Method/" data-id="cidcgcnye000bf4ff9gso4d4l" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/08/11/Proximal-Gradient-Method/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Optimization-Method/">Optimization Method</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Linear-Disciminant-Analysis" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/08/01/Linear-Disciminant-Analysis/" class="article-date">
  <time datetime="2015-08-01T21:23:31.000Z" itemprop="datePublished">2015-08-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/01/Linear-Disciminant-Analysis/">Linear Disciminant Analysis</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Introduction">Introduction</h2><p>In machine learning and data mining applications, the data points usually lie in a high dimension space. Therefore, it’s better to perform dimension reduction to these data points. There are two widely used methods, that is PCA and LDA. </p>
<ol>
<li>PCA is an unsupervised method. It performs dimensionality reduction while preserving as much of the variance in the high dimensional space as possible. In fact, it projects data in the directions of maximum variance. However, the directions of maximum variance may be useless for classification.</li>
<li>LDA is a supervised method. It performs dimensionality reduction while preserving as much of the class discriminatory information as possible, which means that it projects to a line which preserves direction useful for data classification.</li>
</ol>
<h2 id="Main_Idea">Main Idea</h2><pre><code><span class="attribute">Objective</span>: <span class="string">maximise the between-class separability while minimising their within-class variability</span>

<span class="livecodeserver">Solution: maximizing <span class="operator">the</span> difference between <span class="operator">the</span> means, normalized <span class="keyword">by</span> <span class="operator">a</span> measure <span class="operator">of</span> <span class="operator">the</span> <span class="operator">within</span>-class scatter. </span>
</code></pre><ol>
<li><p>Two classes case<br>Given a set of D-dimensional samples ${x_1,x_2,\cdots, x_n}$, $N_1$ of which belong to class $w_1$, and $N_2$ to class $w_2$. We seek to a projection that projects the sample $x$ onto a line<br>$$<br>y = w^Tx<br>$$<br>To mesure the separation, we use the distance of the projected mean of the two classes.<br>$$<br>|\widetilde \mu_1 - \widetilde \mu_2|^2 \\<br>= |\frac{1}{N_1}\sum_{y\in w_1} y - \frac{1}{N_2}\sum_{y\in w_2} y|^2 \\<br>=|\frac{1}{N_1}\sum_{x\in w_1} w^Tx - \frac{1}{N_2}\sum_{x\in w_2}w^Tx|^2 \\<br>= |w^T(\mu_1 - \mu_2)|^2 \\<br>= w^T(\mu_1 - \mu_2)(\mu_1 - \mu_2)^Tw \\<br>= w^T S_b w<br>$$<br>where $S_b=(\mu_1 - \mu_2)(\mu_1 - \mu_2)^T$. However, the distance between projected means is not a good measure since it does not account for the standard deviation within classes, just as shown in the following figure.<br>Therefore, we define the <strong>scatter</strong> for each class.<br>$$<br>\widetilde s_i^{2} = \sum_{y\in w_i}(y-\widetilde \mu_i)^2 \\<br>= \sum_{x\in w_i}(w^Tx-w^T\mu_i)^2 \\<br>= \sum_{x\in w_i}w^T(x-\mu_i)(x-\mu_i)^Tw \\<br>= w^TS_iw<br>$$<br>where $S_i=\sum_{x\in w_i}(x-\mu_i)(x-\mu_i)^T$. Then, we have   $S_w = S_1+S_2 = \sum_{i=1}^c \sum_{x\in w_i}(x-\mu_i)(x-\mu_i)^T$.<br>After that, we have the objective function<br>$$<br>J(w) = \max_{w}\frac{w^TS_bw}{w^TS_w w}<br>$$<br>Note that $S_bx=(\mu_1-\mu_2)(\mu_1-\mu_2)^Tx=\alpha (\mu_1-\mu_2)$, thus $S_bx$ for any sample $x$, it always lies in the same direction as $(\mu_1-\mu_2)$. Therefore, we can solve the eigenvalue problem immediately $w=S_w^{-1}(\mu_1-\mu_2)$.<br>All in all, we are looking for a projection where samples from the same class are projected very close to each other and, at the same time, the projected means are as farther apart as possible.</p>
</li>
<li><p>Multiple classes case<br>For $C$-classes case, we will need $C-1$ projecting directions $W=[w_1,w_2,\cdots,w_{c-1}]$ to get $y=W^Tx$.<br>Then, the <strong>within-class scatter</strong> is as follows<br>$$<br>S_W=\sum_{i=1}^{C}S_i \<br>=\sum_{i=1}^{C} \sum_{x\in w_i} (x-\mu_i)(x-\mu_i)^T<br>$$<br>where $\mu_i=\frac{1}{N_i}\sum_{x\in w_i}x$. The <strong>between-class scatter</strong> is as follows<br>$$<br>S_B = \sum_{i=1}^{C}N_i(\mu_i-\mu)(\mu_i-\mu)^T<br>$$<br>where $\mu=\frac{1}{N}\sum x$. Note that $S_T=S_B+S_W$ is the <strong>total scatter</strong>.<br>However, $W^TS_WW$ and $W^TS_BW$ are matrix rather than scalar. To convert it as a scalar. There are two widely used methods as follows<br>$$<br>J(W) = \max_{W}\frac{|W^TS_WW|}{|W^TS_BW|}<br>$$<br>or<br>$$<br>J(W) = \max_{W}\frac{tr(W^TS_WW)}{tr(W^TS_BW)}<br>$$<br>As we know, the determinant is equal to the multiplication of the eigenvalue of the matrix, and the trace of a matrix is equal to the sum of its eigenvalue.</p>
</li>
</ol>
<ul>
<li>For the det-objective function, we can solve the generalized eigenvalue problem $S_Bw=\lambda S_Ww$ to get the solution. </li>
<li>For the trace-objective function, it is a trace ratio problem. We can solve it with Iterative Trace Ratio (ITR) method. GIven $\lambda_t$ at each iteration $t$, one searches for a transform matrix according to the trace difference as<br>$$<br>W_t = \arg\max_{W}tr(W^T(S_W-\lambda S_B)W)<br>$$<br>and renew $\lambda_{t+1}$ as the trace ratio given by $W_t$:<br>$$<br>\lambda_{t+1} =\frac{tr(W_t^TS_WW_t)}{tr(W_t^TS_BW_t)}<br>$$<br>Note that $S_B$ is the sum of $C$ matrices of $rank\leq 1$ and the mean vectors are constrained by $\frac{1}{C}\sum_{i=1}^{C}\mu_i=\mu$, therefore</li>
<li>$S_B$ will be of rank $C-1$ or less</li>
<li>This means that only $C-1$ of the eigenvalues will be non-zero.</li>
</ul>
<h2 id="Limitations">Limitations</h2><ul>
<li>LDA produces at most $C-1$ feature projections</li>
<li>LDA assumes the data points from different classes follow Gaussian distribution with same covariance. Since the covariance matrix determines the shape of the Gaussian density, in LDA, the Gaussian densities for different classes have the same shape, but are shifted versions of each other (different mean vectors). If the distributions are significantly non-Gaussian or Gaussian-with-different-covariance, the LDA projections may not preserve complex structure in the data needed for classification.</li>
</ul>
<h2 id="Revisit_LDA_from_Gaussian_View">Revisit LDA from Gaussian View</h2><p>In <a href="http://yyyouc.github.io/2015/07/18/Bayesian-Decision-Theory/" target="_blank" rel="external">Bayesian Decision Theory</a>, we have talked about how to design a Bayes classifier. In fact, it needs the class-conditional probability density $p(x|w_i)$ and the prior probability $P(w_i)$. After that, according to the Bayes rule, what we need is to compute the posterior probability $P(w_i|x)$.<br>Under LDA we assume that the density for $X$, given every class $k$ is following a Gaussian distribution. Here is the density formula for a multivariate Gaussian distribution:<br>$$<br>f_k(x) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}}e^{\frac{1}{2}(x-\mu_k)^T\Sigma_k^{-1}(x-\mu_k)}<br>$$<br>where $p$ is the dimension and $\Sigma_k$ is the covariance matrix. <strong>For Linear discriminant analysis (LDA): $\Sigma_{k}=\Sigma, \forall k$</strong>.</p>
<p>As told in Bayesian Decision Theory, we can choose the following discriminant function<br>$$<br>G(x) = \arg\max_{k}P(w_i|x) \\<br>= \arg\max_{k}f_k(x)\pi_k \\<br>= \arg\max_{k}log(f_k(x)\pi_k) \\<br>= \arg\max_{k} [-log((2\pi)^{p/2}|\Sigma|^{1/2})-\frac{1}{2}(x-\mu_k)^T\Sigma_k^{-1}(x-\mu_k) + log(\pi_k)] \\<br>= \arg\max_{k} [-\frac{1}{2}(x-\mu_k)^T\Sigma_k^{-1}(x-\mu_k) + log(\pi_k)] \\<br>= \arg\max_{k} [x^T\Sigma^{-1}\mu_k -\frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k+log(\pi_k)]<br>$$<br>This is the final classifier. Apparently, it is a linear function with respect to $x$. Given any $x$, you simply plug into this formula and see which $k$ maximizes this <a href="https://onlinecourses.science.psu.edu/stat557/book/export/html/35" target="_blank" rel="external">2</a>. </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/08/01/Linear-Disciminant-Analysis/" data-id="cidcgcnyh000df4ffmua7ysg5" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/08/01/Linear-Disciminant-Analysis/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Subgradient-Method" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/07/29/Subgradient-Method/" class="article-date">
  <time datetime="2015-07-29T13:24:51.000Z" itemprop="datePublished">2015-07-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/29/Subgradient-Method/">Subgradient Method</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Introduction">Introduction</h2><p>Gradient descent method is widely used in solving the optimization method. However, it needs the gradient of the objective function. Therefore, how to do for the nondifferentiable function? In this work, we will talk about the subgradient method for the nondifferentaible convex funtion.</p>
<h2 id="Definition">Definition</h2><p>$g$ is a subgradient of a convex funtion $f$ at $x\in dom f$ if<br>$$<br>f(y)\geq f(x)+g^T(y-x)<br>$$<br>for any $y \in dom f$. </p>
<p>Note that there may be more than one subgradient at a certain point, just as shown in the following picture.</p>
<h2 id="Subgradient_Method">Subgradient Method</h2><p>To minimize a nondifferentiable convex function $f$: choose $x_0$ and repeat<br>$$<br>x_k= x_{k-1}-t_kg_{k-1}<br>$$<br>where $g_{k-1}$ is any subgradient of $f$ at $x_{k-1}$, $t_k$ is the step size.</p>
<p>There are three strategies to choose a valid step size:</p>
<ol>
<li>fixed step: $t_k$ is constant.</li>
<li>fixed length: $t_k||g_{k-1}||_2$ is constant (i.e. ||x_k - x_{k-1}||_2 is constant)</li>
<li>dimishing step: $t_k \rightarrow 0$, $\sum_{k=1}^{\infty} t_k = \infty$</li>
</ol>
<p>If $f$ is Lipschitz continous with constant $G&gt;0$:<br>$$<br>|f(x)-f(y)|\leq G||x-y||_2, \forall  x, y<br>$$<br>which is equivalent to<br>$$||g||_2 \leq G, \forall g\in \partial f(x), \forall x $$</p>
<h2 id="Convergence_Analysis">Convergence Analysis</h2><p>Note that <strong>the subgradient method is not a descent method</strong>, the key quantity in the analysis is the distance to the optimal set.</p>
<p>$$<br>||x_k-x^{opt}||_2^2=||x_{k-1}-tg_{k-1}-x^{opt}||_2^2 \\<br>= ||x_{k-1}-x^{opt}||_2^2-2tg_{k-1}^T(x_{k-1}-x^{opt})+t^2||g_{k-1}||_2^2  \\<br>\leq ||x_{k-1}-x^{opt}||_2^2-2tg_{k-1}^T(f_{k-1}-f^{opt})+t^2||g_{k-1}||_2^2<br>$$<br>If we define $f_{k}^{best} = \min_{0\leq i &lt; k}f(x_i)$, then<br>$$<br>2(\sum_{i=1}^k t_i)(f_{k}^{best} - f^{opt}) \\<br>\leq ||x_0 - x^{opt}||_2^2-||x_k-x^{opt}||_2^2+\sum_{i=1}^k t_i^2||g_{i-1}||_2^2 \\<br>\leq ||x_0 - x^{opt}||_2^2+\sum_{i=1}^k t_i^2||g_{i-1}||_2^2<br>$$</p>
<ol>
<li><p>for fixed step size $t_i=t$<br>$$<br> f_{k}^{best} - f^{opt} \leq \frac{||x_{0}-x^{opt}||_2^2}{2kt}+\frac{G^2t}{2}<br>$$</p>
<p> Note that</p>
<ol>
<li>it does not guarantee convergence of $f_{k}^{best}$</li>
<li>for large $k$, $f_{k}^{best}$ is approximately $G^2t/2$-suboptimal. </li>
</ol>
</li>
<li><p>for fixed step length $_i=s/||g_{i-1}||_2$<br>$$<br> f_{k}^{best} - f^{opt} \leq \frac{G||x_{0}-x^{opt}||_2^2}{2ks}+\frac{Gs}{2}<br>$$<br> Note that </p>
<ol>
<li>it does not guarantee converfence of $f_{k}^{best}$</li>
<li>for large $k$, $f_{k}^{best}$ is approximately $Gs/2$-suboptimal. </li>
</ol>
</li>
<li><p>for diminishing step size $t_k \rightarrow 0$, $\sum_{k=1}^{\infty} t_k = \infty$<br>$$<br>f_{k}^{best} - f^{opt} \leq \frac{G||x_{0}-x^{opt}||_2^2+G^2\sum_{i=1}^k t_i^2}{2\sum_{i=1}^k t_i}<br>$$<br>Because $\frac{\sum_{i=1}^k t_i^2}{\sum_{i=1}^k t_i}\rightarrow 0$, $f_{k}^{best}$ converges to $f^{opt}$.</p>
</li>
</ol>
<p>Note that if $s_i=t_i||g_{i-1}||_2$ and $||x_0-x^{opt}||_2\leq R$, we have<br>$$<br>f_{k}^{best} - f^{opt} \leq \frac{R^2+\sum_{i=1}^{k}s_i^2}{2\sum_{i=1}^{k}s_i/G}<br>$$<br>For given $k$, such a bound can be minimized by fixed step length $s_i=s=R/\sqrt k$, then we have<br>$$<br>f_{k}^{best} - f^{opt} \leq \frac{GR}{\sqrt k}<br>$$<br>which means that it needs $k=O(1/\epsilon^2)$ iterations to get $f_{k}^{best} - f^{opt} \leq \epsilon$</p>
<h2 id="Summary">Summary</h2><ol>
<li>It can handle nondifferentiable convex problem.</li>
<li>The convergence is very slow. It needs $O(1/\epsilon^2)$ iterations to find $\epsilon$-suboptimal point.</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/07/29/Subgradient-Method/" data-id="cidcgcnya0009f4fftivb0smz" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/07/29/Subgradient-Method/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Optimization-Method/">Optimization Method</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Gradient-Descent-Method" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/07/24/Gradient-Descent-Method/" class="article-date">
  <time datetime="2015-07-25T02:16:54.000Z" itemprop="datePublished">2015-07-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/24/Gradient-Descent-Method/">Gradient Descent Method</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Gradient method lays the foundation of the optimization algorithm. Thus, we will talk about its basic idea and its convergence in this work.</p>
<h2 id="Definition">Definition</h2><p>In general, we assume that </p>
<ol>
<li>$f(x)$ is convex and differentiable with $dom f = \Re^n$</li>
<li>$\nabla f(x)$ is Lipschitz continous with parameter $L&gt;0$</li>
</ol>
<p>The general form is as follows,<br>$$<br>x_{k+1}=x_{k}-t_k\nabla f(x_k)<br>$$<br>where $\nabla f(x_k)$ is the gradient, $t_k$ is the step size. There are three strategies to determine the step size.</p>
<ol>
<li>Fixed: $t_k$ is constant</li>
<li>exact line search: minimize $f(x-t\nabla f(x))$ over $t$</li>
<li>backtracking line search:</li>
</ol>
<p>The first strategy is the simplest one. Indeed, it is often used, but only in convex optimization, where the behavior of functions is much more predictable than in the general nonlinear case.</p>
<p>The second strategy is completely theoretical. It is never used in practice since even in one-dimensional case we cannot find an exact minimum of a function in finite time.</p>
<p>The third strategy is used in the majority of the practical algorithms. We will talk about this strategy in the future work.</p>
<h2 id="Convergence_of_General_Convex_Function">Convergence of General Convex Function</h2><p>Since $f$ is Lipschitz continous, therefore, for $x_{k+1}=x_{k}-t\nabla f(x)$, we have<br>$$<br>f(x_{k+1})\leq f(x_{k})-\nabla f(x)^T(x_{k+1}-x_{k}) + \frac{L}{2}||x_{k+1}-x_{k}||_2^2 = f(x_k)-t(1-\frac{Lt}{2})||\nabla f(x)||_2^2<br>$$<br>If we set $t\leq 1/L$, then<br>$$<br>f(x_{k+1})\leq f(x_{k})- \frac{t}{2} ||\nabla f(x_k)||_2^2 \\<br>\leq f(x^{opt})+ \nabla f(x_k)^T(x_k-x^{opt})- \frac{t}{2} ||\nabla f(x_k)||_2^2 \\<br>= f(x^{opt})+ \frac{1}{2t} (||x_k-x^{opt}||_2^2-||x_k-x^{opt}||_2^2 + 2t \nabla f(x_k)^T(x_k-x^{opt})-t^2 ||\nabla f(x_k)||_2^2) \\<br>= f(x^{opt})+ \frac{1}{2t} (||x_k-x^{opt}||_2^2 - ||x_k-x^{opt}-t\nabla f(x_k)||_2^2) \\<br>= f(x^{opt})+ \frac{1}{2t} (||x_k-x^{opt}||_2^2 - ||x_{k+1}-x^{opt}||_2^2)<br>$$</p>
<p>Therefore, we have<br>$$<br>\sum_{i=1}^k (f(x_i)-f(x^{opt})) \leq \frac{1}{2t}\sum_{i=1}^k (||x_{i-1}-x^{opt}||_2^2-||x_{i}-x^{opt}||_2^2) \\<br>= \frac{1}{2t} (||x_{0}-x^{opt}||_2^2-||x_{k}-x^{opt}||_2^2) \\<br>\leq \frac{1}{2t} ||x_{0}-x^{opt}||_2^2<br>$$<br>Since $f(x_i)$ is non-increasing, we have<br>$$<br>f(x_k)-f(x^{opt}) \leq \frac{1}{k} \sum_{i=1}^k (f(x_i)-f(x^{opt})) \leq \frac{1}{2kt} ||x_{0}-x^{opt}||_2^2<br>$$</p>
<p>As a result, the number of iterations to reach $f(x_k)-f(x^{opt}) \leq \epsilon$ is $O(1/ \epsilon)$.</p>
<h2 id="Convergence_of_Strongly_Convex_Function">Convergence of Strongly Convex Function</h2><p>For strongly convex function, we have<br>$$<br>f(y)\geq f(x)+\nabla f(x)^T(y-x)+\frac{\mu}{2}||y-x||_2^2<br>$$</p>
<p>If $x_{k+1}=x_{k}-t\nabla f(x)$ and $0&lt; t \leq 2/(\mu+L)$, we have<br>$$<br>||x_{k+1}-x^{opt}||_2^2=||x_k-t \nabla f(x_k)-x^{opt}||_2^2 \\<br>= ||x_{k}-x^{opt}||_2^2 - 2t\nabla f(x_k)^T(x_k-x^{opt})+t^2||\nabla f(x_k)||_2^2 \\<br>\leq (1-t\frac{2mL}{m+L})||x_k-x^{opt}||_2^2+t(t-\frac{2}{m+L})||\nabla f(x_k)||_2^2 \\<br>\leq (1-t\frac{2mL}{m+L})||x_k-x^{opt}||_2^2<br>$$<br>Thus, $||x_k-x^{opt}||_2^2 \leq (1-t\frac{2mL}{m+L})^k ||x_0-x^{opt}||_2^2$ , which implies linear convergence.</p>
<p>Due to the quadratic upper bound of function with Lipschitz continous gradient, we have<br>$$<br>f(x_{k})-f(x^{opt}) \leq \frac{L}{2}||x_{k}-x^{opt}||_2^2 \leq \frac{c^k L}{2}||x_{0}-x^{opt}||_2^2<br>$$<br>As a result, the number of iterations to reach $f(x_k)-f(x^{opt}) \leq \epsilon$ is $O(log(1/ \epsilon))$.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/07/24/Gradient-Descent-Method/" data-id="cidcgcnyj000ff4ff240ozf1c" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/07/24/Gradient-Descent-Method/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Optimization-Method/">Optimization Method</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Convex-Function" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/07/21/Convex-Function/" class="article-date">
  <time datetime="2015-07-21T19:39:44.000Z" itemprop="datePublished">2015-07-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/21/Convex-Function/">Convex Function</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>In this work, we will talk about some properties of convex function, which are usually used in the optimization algorithm. </p>
<h1 id="1-_Convexity">1. Convexity</h1><h2 id="1-1_Definition">1.1 Definition</h2><p>$f$ is convex if $dom f$ is a convex set and Jensen’s inequality holds:<br>$$<br>f(\theta x+(1-\theta) y)\leq \theta f(x)+(1-\theta)f(y)<br>$$<br>for all $x,y\in dom f$ and $\theta \in [0,1]$.</p>
<h2 id="1-2_First-order_condition">1.2 First-order condition</h2><p>For differentiable $f$,<br>$$<br>f(y)\geq f(x)+ \nabla f(x)^T(y-x)<br>$$<br>for all $x,y\in dom f$</p>
<h2 id="1-3_Second-order_condition">1.3 Second-order condition</h2><p>For twice differentiable $f$,<br>$$<br>\nabla^2 f(x) \geq 0<br>$$<br>for all $x \in dom f$</p>
<h1 id="2-_Lipschitz_Continuous_Gradient">2. Lipschitz Continuous Gradient</h1><h2 id="2-1_Definition">2.1 Definition</h2><p>Gradient of $f$ is Lipchitz continous with parameter $L&gt;0$ if<br>$$<br>||\nabla f(x)-\nabla f(y)||_2 \leq L||x-y||_2<br>$$<br>for all $x,y\in dom f$</p>
<ul>
<li>Note that the definition does not assume convexity of $f$</li>
<li>For convex $f$ with $dom f=R^n$, it is equivalent to $\frac{L}{2}x^Tx-f(x)$ is convex.<br>(i.e. if $f$ is twice differentiable and convex, $0 \leq \nabla^2 f(x) \leq LI$ for all $x$)</li>
<li>Note that Lipchitz continuity gives a constraint to $f$, which is that $f$ cannot change dramatically.</li>
</ul>
<h2 id="2-2_Quadatic_upper_bound">2.2 Quadatic upper bound</h2><p>Suppose $\nabla f$ is Lipschitz continous with parameter $L$ and $dom f$ is convex, then<br>$$<br>f(y)\leq f(x) + \nabla f(x)^T(y-x)+\frac{L}{2}||y-x||_2^2<br>$$<br>for all $x,y\in dom f$.</p>
<p>Therefore, for convex $f$ with Lipschitz continous gradient, we have<br>$$<br>f(x) + \nabla f(x)^T(y-x) \leq f(y)\leq f(x) + \nabla f(x)^T(y-x)+\frac{L}{2}||y-x||_2^2<br>$$<br>Just as shown in the following figure.</p>
<h1 id="3-_Strongly_Convex_Function">3. Strongly Convex Function</h1><h2 id="3-1_Definition">3.1 Definition</h2><p>Function $f$ is strongly convext with parameter $\mu&gt;0$ if function<br>$$<br>g(x)=f(x)-\frac{\mu}{2}x^Tx<br>$$<br>is convex.</p>
<h2 id="3-2_First-order_condition">3.2 First-order condition</h2><p>For differentiable $f$,<br>$$<br>f(y)\geq f(x)+\nabla f(x)^T(y-x)+\frac{\mu}{2}||y-x||_2^2<br>$$<br>for all $x,y\in dom f$. It is also called <strong>quadratic lower bound</strong>, just as shown in following figure.</p>
<h2 id="3-3_Second-order_condition">3.3 Second-order condition</h2><p>For twice differentiable $f$,<br>$$<br>\nabla^2 f(x) \geq \mu I<br>$$<br>for all $x \in dom f$.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/07/21/Convex-Function/" data-id="cidcgcnyn000jf4ffnasgcvgr" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/07/21/Convex-Function/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Optimization-Method/">Optimization Method</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Density-Estimation" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/07/20/Density-Estimation/" class="article-date">
  <time datetime="2015-07-21T00:21:14.000Z" itemprop="datePublished">2015-07-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/20/Density-Estimation/">Density Estimation</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Introduction">Introduction</h1><p>In <a href="http://yyyouc.github.io/2015/07/18/Bayesian-Decision-Theory/" target="_blank" rel="external">Bayesian Decision Theory</a>, we have talked about how to design a Bayes classifier. In fact, it needs the class-conditional probability density $p(x|w_i)$ and the prior probability $p(w_i)$. But how to get $p(x|w_i)$ and $p(w_i)$? In practice, it is easy to get $p(w_i)$. Therefore, we will mainly talk about how to estimate the class-conditional probability density based on the given dataset.</p>
<p>There are two category method about estimate density. That is <strong>parametric method</strong> and <strong>nonparametric method</strong>. For the parametric method, it assumes that the dataset follows a specific functional form for the distribution with unknown parameters. Then density estimation is transformed to the parameter estimation. For the nonparametric method, the form of the distribution typically depends on the size of the dataset. For example, the histogram method. </p>
<p>In the following, we will talk about the parametric method. The parametric method includes two kinds of method: <strong>maximum likelihood</strong> and <strong>Bayesian method</strong>. </p>
<ul>
<li>Maximum likelihood assumes the samples follows a specific form of distribution whose parameters are <strong>fixed</strong> but unknown. Thus, this method is to estimate the <strong>value of the parameter</strong>. The best estimate of their value is defined to be the one that maximizes the probability of obtaining the samples actually observed.<ul>
<li>Bayesian method views the samples follows a specific form of distribution whose parameters are <strong>random variables</strong> having some known a priori distribution. Thus, this method is to estimate the <strong>distribution of the parameter</strong>, that is the posterior distribution of the parameter.</li>
</ul>
</li>
</ul>
<h2 id="Maximum_Likelihood_Estimation">Maximum Likelihood Estimation</h2><p>As above, we have already know the form of the distribution, but we do not know the value of the parameters. Thus, we need to estimate the value of the parameters. </p>
<p>Denote the parameter as $\theta$, and the $i$-th class (we assume different class has different parameter and they do not affect each other) dataset $D={x_1, x_2,\cdots, x_n}$ drawn independently from the probability density $p(x|\theta)$. Our duty is to estimate the unkown parameter $\theta$ according to dataset $D$.</p>
<p>It is easy to know<br>$$<br>p(D|\theta)=\prod_{i=1}^np(x_i|\theta)<br>$$<br>where $p(D|\theta)$ is called the $likelihood$ of $\theta$ with respect to the set of samples. The maximum likelihood estimate of $\theta$ is the value that maximizes $p(D|\theta)$. Intuitively, <strong>this estimate corresponds to the value of $\theta$ that in some sense best agrees with or supports the actually observed training samples</strong>.</p>
<p>To get the optimal $\theta$, we define the log-likelihood function<br>$$<br>l(\theta)=lnp(D|\theta)=\sum_{i=1}^nlnp(x_i|\theta)<br>$$<br>We can take the derivative of $l(\theta)$ with respect to $\theta$ and set it as zero to get the optimal $\theta$.</p>
<p>This is the basic idea of maximum likelihood estimation.</p>
<h2 id="Bayesian_Estimation">Bayesian Estimation</h2><p>Bayesian estimation also knows the form of the distribution with unkown parameters. But the parameters are random variables, following a prior distribution. Thus, our duty is to estimate such a distribution. That is the posterior distribution of the unkown paramethers.</p>
<p>Denote $p(x|D)$ as the desired class-conditional probability density where $D$ is the training samples and $x$ is the testing sample, then<br>$$<br>p(x|D)=\int p(x,\theta|D)d\theta=\int p(x|\theta)p(\theta|D)d\theta<br>$$<br>where $p(\theta|D)$ is the the posterior density for the unknown parameter, $p(x|\theta)$ is the class-conditional probability density with unkown parameters $\theta$. Therefore, once we know the distribution $p(\theta|D)$, we will know $p(x|\theta)$. At last, we can get the desired class-conditional probability density $p(x|D)$. Thus, <strong>the most important is to estimate $p(\theta|D)$</strong>.</p>
<p>According to Bayes’ formula<br>$$<br>p(\theta|D)=\alpha p(D|\theta)p(\theta)=\alpha \prod_{i=1}^np(x_i|\theta)p(\theta)<br>$$<br>where $p(\theta)$ is the prior probability density and $p(x_i|\theta)$ is the class-conditional probability density with unkown parameters $\theta$.</p>
<p>This is the basic idea of Bayesian estimation.</p>
<p>All in all, the maximum likelihood approach estimates a point in $\theta$ space, the Bayesian approach instead estimates a distribution.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/07/20/Density-Estimation/" data-id="cidcgcnyl000hf4ffq7p9z2pu" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/07/20/Density-Estimation/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Bayesian-Decision-Theory" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/07/18/Bayesian-Decision-Theory/" class="article-date">
  <time datetime="2015-07-19T01:38:12.000Z" itemprop="datePublished">2015-07-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/18/Bayesian-Decision-Theory/">Bayesian Decision Theory</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Introduction">Introduction</h2><p>Bayesian decision theory is a fundamental statistical method to the problem of pattern classification. It is to use the probability to perform classification decision. It has two assumptions:</p>
<ul>
<li>the decision problem is posed in probilistic terms;</li>
<li>all the involved probability values are known.</li>
</ul>
<h2 id="Bayes_Formula">Bayes Formula</h2><p>Bayes formula is the basis of the Bayesian decision theory. It is defined as follows:<br>$$<br>P(w_j|x)=\frac{p(x|w_j)P(w_j)}{p(x)}<br>$$<br>where $P(w_j|x)$ is the <strong>posterior probability</strong>, $P(w_j)$ is the <strong>prior probability</strong> and $p(x|w_j)$ is the <strong>conditional probability density</strong>. And $p(x)=\sum_{j=1}^{n}p(x|w_j)P(w_j)$.<br>But what is the meaning of prior probability, posterior probability and the conditional probability density?</p>
<ul>
<li>Prior probability is the assumption that we give to a problem. It may be correct or not. However, we can use conditional probability density to justify it.</li>
<li>Conditional probability density is the likelihood of $w_j$ with respect to $x$. If it is large, it means that $w_j$ is more “likely” to be the true category.</li>
<li>Posterior probability is the justified assumption. </li>
</ul>
<p>In fact, given a data point, we can give an assumption about the category which it belongs to. Such assumption maybe right or not. However, such a data point has some features. Therefore, under such a assumption, we can use these features of the data point to justify whether the assumtion is proper. If so, we will get a large posterior probability. Otherwise, we will get a small one.<br>This is the basic idea of Bayes formula. It can be interpreted as follows:<br>$$<br>posterior = \frac{likelihood\times prior}{evidence}<br>$$<br>This formula shows that by observing the value of $x$ we can convert the prior probability $P(w_j)$to the a  posterior probability $P(w_j|x)$.</p>
<h2 id="Loss_Function">Loss Function</h2><p>Now we can use Bayes formula to give decision about the classification. But how to measure the cost of our decision?</p>
<p>Since $P(w_j|x)$ is the probability that the true state of nature is $w_j$ , the expected loss associated with taking action $\alpha_i$ is<br>$$<br>L(\alpha_i|x)=\sum_{j=1}^{c}I(\alpha_i|w_j)P(w_j|x)<br>$$<br>In decision-theoretic terminology, an expected loss is called a <strong>risk</strong>, and $L(\alpha_i|x)$ is called the <strong>conditional risk</strong>. Whenever we encounter a particular observation $x$, we can minimize our expected loss by selecting the action that minimizes the conditional risk. Since $L(\alpha_i|x)$ is the conditional risk, <strong>overall risk</strong> is given by<br>$$<br>L=\int L(\alpha(x)|x)p(x)dx<br>$$<br>Clearly, if $\alpha(x)$ is chosen such that $L(\alpha(x))$ is as small as possible for every $x$, then the overall risk will be minimized. This justifies the following statement of the Bayes decision rule: To minimize the overall risk, compute the conditional risk<br>$$<br>L(\alpha_i|x)=\sum_{j=1}^{c}I(\alpha_i|w_j)P(w_j|x)<br>$$<br>and select the action $\alpha_i$ for which $L(\alpha_i|x)$ is minimum. The resulting minimum overall risk is called the <strong>Bayes risk</strong>.</p>
<p>Now, let us define a function<br>$$<br>I(\alpha_j|w_i)=\left\{<br>\begin{aligned}<br>0 &amp;&amp; i=j \\<br>1 &amp;&amp; i \neq j \\<br>\end{aligned}<br>\right.<br>$$<br>Then, the conditional risk can be defined as follows.<br>$$<br>L(\alpha_i|x)=\sum_{j=1}^{c}I(\alpha_i|w_j)P(w_j|x) \<br>= \sum_{j\neq i}P(w_j|x) \<br>= 1-P(w_i|x)<br>$$<br>From the definition of the loss function, we can conclude that minimizing loss function $L(\alpha_i|x)$ is to maximize the posterior probability $P(w_j|x)$. In other words, decide $w_i$ if $P(w_i|x)&gt;P(w_j|x)$ for all $j\neq i$</p>
<h2 id="Bayes_Classifier">Bayes Classifier</h2><p>There are many different ways to represent pattern classifiers. One of the most useful is in terms of a set of <strong>discriminant functions</strong> $g_i(x), i = 1\cdots c$. The classifier is said to assign a data point $x$ to class $w_i$ if for all $j\neq i$<br>$$<br>g_i(x)&gt;g_j(x)<br>$$</p>
<p>A Bayes classifier is easily and naturally represented in this way. For the general case with risks, we can let $g_i(x) = -L(\alpha_i|x)$, since the maximum discriminant function will then correspond to the minimum conditional risk. For the minimum-error-rate case, we can simplify things further by taking $g_i(x) = P(w_j|x)$, so that the maximum discriminant function corresponds to the maximum posterior probability.</p>
<p>Clearly, the choice of discriminant functions is not unique. We can always multiply all the discriminant functions by the same positive constant or shift them by the same additive constant without influencing the decision. More generally, if we replace every $g_i(x)$ by $f(g_i(x))$, where $f(.)$ is a monotonically increasing function, the resulting classification is unchanged. This observation can lead to significant analytical and computational simplifications. In particular, for minimum-error-rate classification, any of the following choices gives identical classification results, but some can be<br>much simpler to understand or to compute than others:<br>$$<br>g_i(x)=P(w_i|x) \\<br>g_i(x) = p(x|w_i)P(w_i) \\<br>g_i(x) = lnp(x|w_i)+lnP(w_i)<br>$$</p>
<p>Even though the discriminant functions can be written in a variety of forms, the decision rules are equivalent. The effect of any decision rule is to divide the feature space into $c$ decision regions, $R_1,\cdots, R_c$. If $g_i(x) &gt; g_j(x)$ for all $j\neq i$, then $x$ is in region $R_i$, and the decision rule calls for us to assign $x$ to $w_i$. The regions are separated<br>by decision boundaries, surfaces in feature space where ties occur among the largest discriminant functions.</p>
<h2 id="Naïve_Bayes_Method">Naïve Bayes Method</h2><p>Naïve Bayes is a subset of Bayesian decision theory. It uses the Bayesian decision theory to do classification. Here, Naïve means the features of the data point are independent to each other.</p>
<p>Given a data point $x=(x_1, x_2,\cdots,x_n)$ where $x_i$ is the $i$-th feature of the data point, and given classes $c_1, c_2, \cdots, c_k$. If $P(c_i|x)&gt;P(c_j|x)$ for all $j\neq i$, then data point $x$ belongs to class $c_i$. Specifically,<br>$$<br>P(c_i|x)=\frac{p(x|c_i)P(c_i)}{p(x)}<br>$$<br>Due to the independence of the features, $p(x|c_i)=p(x_1|c_i)p(x_2|c_i)\cdots p(x_n|c_i)$.</p>
<p>This is the basic idea of Naïve Bayes method.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/07/18/Bayesian-Decision-Theory/" data-id="cidcgcnys000lf4ff0lbgsy5n" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/07/18/Bayesian-Decision-Theory/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Support Vector Machine" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/07/07/Support Vector Machine/" class="article-date">
  <time datetime="2015-07-08T04:09:39.000Z" itemprop="datePublished">2015-07-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/07/Support Vector Machine/">Support Vector Machine</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Introduction">Introduction</h2><p>When it comes to classification methods, there are two categories. The first category is to construct a <strong>discriminant function</strong> for each class, and then classify each sample to the class with the largest value for its discriminant function, such as logistic regression method. The second method is to construct a <strong>separating hyperplane</strong>, such as perceptron method and SVM.</p>
<h2 id="Objective_function">Objective function</h2><p>SVM is to find an optimal separating hyperplane among different classes such that the <strong>margin</strong> is maximized, where margin is the smallest distance between the separating plane and any of the samples. </p>
<p>The objective function is as follows,<br>$$\max_{w,b} margin(w, b) \\<br>s.t. y_i(w^Tx_i+b)&gt;0$$<br>where $margin(w,b)=\min_{i=1,2,..,N}distance(x_i,w,b)$, and $distance(x_i, w, b)=\frac{|w^Tx_i+b|}{||w||}=\frac{y_i(w^Tx_i+b)}{||w||}$. The constraint means that we are only interested in the hyperplane for which all samples are correctly classified.</p>
<p>Due to the linearity of the hyperplane, there exists many representations for the same hyperplane, for example, $(kw)^Tx+kb=0$. To avoid such cases, we scale $w$ and $b$ such that $\min_{i=1,2,..,N} y_i(w^Tx_i+b)=1$. Thus, $margin(w,b)=\frac{1}{||w||}$. Thus, the objective function is as follows.<br>$$ \max_{w,b}\frac{1}{||w||} \\<br>s.t. y_i(w^Tx_i+b)\geq1 $$<br>It is equivalent to the following:<br>$$ \min_{w,b}\frac{1}{2}w^Tw \\<br>s.t. y_i(w^Tx_i+b)\geq1 $$</p>
<h2 id="Optimization_algorithm">Optimization algorithm</h2><p>There are two methods to solve this objective function. The first method is to solve the primal problem directly. The second method is to solve the dual problem.</p>
<h3 id="1-_Primal_problem">1. Primal problem</h3><p>This problem is a quadratic programming (QP) problem. It can be solved directly by many optimization tools. The general form of the QP problem is as follows.<br>$$\min_{u} \frac{1}{2}u^TQu+p^Tu \\<br>s.t.a_i^Tu\geq c_i , i=1,…,m<br>$$<br>The objective function of SVM can be represented as such form, where $u=\left[<br>  \begin{array}{c}<br>    b\\ w<br>  \end{array}<br>\right] $, $Q=\left[<br>  \begin{array}{cc}<br>    0 &amp; 0_d^T \\<br>    0_d &amp; I_d<br>  \end{array}<br>\right] $, $p=0_{d+1}$, $a_i^T=y_i[1,  x_i^T]$,$c_i=1$. For this method, the number of the variables is $d$ (the number of features), and the number of the constraints is $N$ (the number of samples). If $d$ is very large, especially for the kernel SVM, the computation will also be very large. How to address this problem? We can solve the dual problem rather than the primal problem.</p>
<h3 id="2-_Dual_problem">2. Dual problem</h3><h4 id="2-1_Duality">2.1 Duality</h4><p>At first, we will talk about some basic knowledge about the dual problem. We consider a standard optimization problem:<br>$$<br>\min f_0(x)  \\<br>s.t. f_i(x) \leq 0, i=1,…,m \\<br>h_i(x) = 0, i=1,…,p<br>$$<br>This is a constrained optimization problem. Ususally it is more difficult to solve than the unconstrained optimization problem. Can we transform it to an unconstrained one? Of course, we define a Lagrangian function as follows:<br>$$L(x,\lambda, v)=f_0(x)+\sum_{i=1}^m\lambda_i f_i(x)+\sum_{i=1}^pv_ih_i(x)$$<br>where $\lambda_i$ and $v_i$ is the Lagrangian multiplier. Note that we put the constraint into the objective function so that it becomes an uncontrained problem. However, are they equivalent?<br>Consider the following function:<br>\begin{equation}<br>\theta_p(x)=\max_{\lambda_i,v_i: \lambda_i\geq 0} L(x, \lambda, v)<br>\end{equation}<br>If some constraint are violated, such as $f_i(x)&gt;0$ or $h_i(x)\neq0$, we can adjust $\lambda_i$ and $v_i$ such that $\theta_p(x)$ approaches to infinity. If all the constraints are satisifed, it is easy to know that $\lambda_i$ should be equal to 0, and then $\theta_p(x)$ is equal to $f_0(x)$ exactly. Thus, we can minimize $\theta_p(x)$ to enforce the constraint to be satisfied, that is<br>\begin{equation}<br>\min_{x}\theta_p(x)=\min_{x} \max_{\lambda_i,v_i: \lambda_i\geq 0} L(x, \lambda, v)<br>\end{equation}<br>then it will be equivalent the standard form. This is the primal problem, in the following we will derive the dual problem. Note that for any $\lambda’$ and $v’$, we have $$\min_{x} \max_{\lambda_i,v_i: \lambda_i\geq 0} L(x, \lambda, v) \geq \min_{x} L(x, \lambda’, v’)$$ (because max $\geq$ any), and then $$\min_{x} \max_{\lambda_i,v_i: \lambda_i\geq 0} L(x, \lambda, v) \geq \max_{\lambda_i’,v_i’: \lambda_i’\geq 0}\min_{x} L(x, \lambda’, v’)$$ (because best is one of any).<br>The right side is the dual problem, and $\min_{x} L(x, \lambda, v)$ is the dual function. Note that the dual problem gives a lower bound to the primal problem. </p>
<p>When the solution $x^{<em>}$, $\lambda^{</em>}$ and $v^{*}$ satisfy the KKT conditions, they are the solution of both primal and dual problems.</p>
<h4 id="2-2_Dual_SVM">2.2 Dual SVM</h4><p>Based on the above foundation, the dual SVM is as follows<br>$$\max_{\alpha_i\geq 0}{\min_{b,w}\frac{1}{2}w^Tw+\sum_{i=1}^{N}\alpha_i(1-y_i(w^Tx_i+b))}$$</p>
<p>At first, we solve the inner problem<br> $$\min_{b,w}\frac{1}{2}w^Tw+\sum_{i=1}^{N}\alpha_i(1-y_i(w^Tx_i+b))$$<br> This is an unconstrained problem. It is easy to solve by setting the direvative with respect to $w$ and $b$ as zero. We can get<br> $$<br> \sum_{i=1}^{N}\alpha_iy_i=0 \\<br> \sum_{i=1}^{N}\alpha_iy_ix_i=w<br> $$<br> Then,<br>$$<br>\frac{1}{2}w^Tw+\sum_{i=1}^{N}\alpha_i(1-y_i(w^Tx_i+b)) \\<br>=\frac{1}{2}w^T\sum_{i=1}^{N}\alpha_iy_ix_i+\sum_{i=1}^{N}\alpha_i-w^T\sum_{i=1}^N\alpha_iy_ix_i-b\sum_{i=1}^N\alpha_iy_i \\<br>=\sum_{i=1}^{N}\alpha_i-\frac{1}{2}w^T\sum_{i=1}^{N}\alpha_iy_ix_i \\<br>= \sum_{i=1}^{N}\alpha_i-\frac{1}{2}(\sum_{i=1}^{N}\alpha_iy_ix_i)^T\sum_{i=1}^{N}\alpha_iy_ix_i \\<br>= \sum_{i=1}^{N}\alpha_i-\frac{1}{2}\sum_{i,j=1}^{N}\alpha_i\alpha_jy_iy_jx_i^Tx_j<br>$$<br>Now we have the dual problem as follows.<br>$$<br>\min \frac{1}{2}\sum_{i=1}^{N}\sum_{j=1}^{N}\alpha_i\alpha_jy_iy_jx_i^Tx_j-\sum_{i=1}^{N}\alpha_i \\<br>s.t. \alpha_i \geq 0, i=1,…,N \\<br> \sum_{i=1}^{N}\alpha_iy_i=0<br>$$<br>This is a QP with $N$ variables and $N+1$ constraints. Therefore, it can be easily solved by optimization tools. Note that when we solve this QP, the matrix $Q$ consists of $q_{ij}=y_iy_jx_i^Tx_j$ usually is dense. Thus, it needs large storage.</p>
<p>After we got the solution of the dual problem, how can we get the primal solution $w$ and $b$? Note that $w=\sum_{i=1}^{N}\alpha_iy_ix_i$. Whats more, according to the KKT dual complementary conditions,$\alpha_i(1-y_i(w^Tx_i+b))=0$, if $\alpha_i&gt;0$, $1-y_i(w^Tx_i+b)=0$, that is $b=y_i-w^Tx_i$. Note that $\alpha_i&gt;0$ means $y_i(w^Tx_i+b)=1$, thus this point locates on the boundary. Such points are called <strong>support vector</strong>. </p>
<p>After obtainning the optimal $w$ and $b$ from the trainning data, we can classify the test data by the following formula.<br>$$<br>w^Tx+b=(\sum_{i=1}^N\alpha_iy_ix_i)^Tx+b=\sum_{i=1}^N\alpha_iy_i x_i^Tx+b<br>$$<br>Note that we only need to calculate the inner product between the testing data and the support vector (corresponds to $\alpha_i&gt;0$) rather than the whole training data, thus it is efficient.</p>
<h2 id="Soft-Margin_SVM">Soft-Margin SVM</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/07/07/Support Vector Machine/" data-id="cidcgcny50006f4ffe3l3r8xc" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/07/07/Support Vector Machine/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/05/17/hello-world/" class="article-date">
  <time datetime="2015-05-18T01:29:05.546Z" itemprop="datePublished">2015-05-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/05/17/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="http://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="http://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="http://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick_Start">Quick Start</h2><h3 id="Create_a_new_post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run_server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate_static_files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy_to_remote_sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/05/17/hello-world/" data-id="cidcgcny20003f4ffy9c0fkhn" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/05/17/hello-world/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hexo/">Hexo</a></li></ul>

    </footer>
  </div>
  
</article>


  
  
</section>
        
          <aside id="sidebar">
  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/">Hexo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Optimization-Method/">Optimization Method</a><span class="tag-list-count">5</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a><a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a><a href="/tags/Optimization-Method/" style="font-size: 20px;">Optimization Method</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/08/">August 2015</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/07/">July 2015</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">May 2015</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2015/08/14/Accelerated-Gradient-Method/">Accelerated Gradient Method</a>
          </li>
        
          <li>
            <a href="/2015/08/11/Proximal-Gradient-Method/">Proximal Gradient Method</a>
          </li>
        
          <li>
            <a href="/2015/08/01/Linear-Disciminant-Analysis/">Linear Disciminant Analysis</a>
          </li>
        
          <li>
            <a href="/2015/07/29/Subgradient-Method/">Subgradient Method</a>
          </li>
        
          <li>
            <a href="/2015/07/24/Gradient-Descent-Method/">Gradient Descent Method</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
			
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 YYY OUC<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    
<script>
  var disqus_shortname = 'yyyouc';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>


<script type="text/x-mathjax-config"> 
MathJax.Hub.Config({ 
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} 
}); 
</script>
<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	



  </div>
</body>
</html>