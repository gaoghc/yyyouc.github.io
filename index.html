<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>YYYOUC</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="YYYOUC">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="YYYOUC">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="YYYOUC">
<meta name="twitter:description">
  
    <link rel="alternative" href="/atom.xml" title="YYYOUC" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">YYYOUC</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="q" value="site:http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Subgradient-Method" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/07/29/Subgradient-Method/" class="article-date">
  <time datetime="2015-07-29T13:24:51.000Z" itemprop="datePublished">2015-07-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/29/Subgradient-Method/">Subgradient Method</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Introduction">Introduction</h2><p>Gradient descent method is widely used in solving the optimization method. However, it needs the gradient of the objective function. Therefore, how to do for the nondifferentiable function? In this work, we will talk about the subgradient method for the nondifferentaible convex funtion.</p>
<h2 id="Definition">Definition</h2><p>$g$ is a subgradient of a convex funtion $f$ at $x\in dim f$ if<br>$$<br>f(y)\geq f(x)+g^T(y-x)<br>$$<br>for any $y \in dom f$. </p>
<p>Note that there may be more than one subgradient at a certain point, just as shown in the following picture.</p>
<h2 id="Subgradient_Method">Subgradient Method</h2><p>To minimize a nondifferentiable convex function $f$: choose $x<em>0$ and repeat<br>$$<br>x_k= x\</em>{k-1}-t_kg_{k-1}<br>$$<br>where $g_{k-1}$ is any subgradient of $f$ at $x_{k-1}$, $t_k$ is the step size.</p>
<p>There are three strategies to choose a valid step size:</p>
<ol>
<li>fixed step: $t_k$ is constant.</li>
<li>fixed length: $t_k||g_{k-1}||_2$ is constant (i.e. ||x_k - x_{k-1}||_2 is constant)</li>
<li>dimishing step: $t_k \rightarrow 0$, $\sum_{k=1}^{\infty} t_k = \infty$</li>
</ol>
<p>If $f$ is Lipschitz continous with constant $G&gt;0$:<br>$$<br>|f(x)-f(y)|\leq G||x-y||_2, \forall  x, y<br>$$<br>which is equivalent to<br>$$||g||_2 \leq G, \forall g\in \partial f(x), \forall x $$</p>
<h2 id="Convergence_Analysis">Convergence Analysis</h2><p>Note that <strong>the subgradient method is not a descent method</strong>, the key quantity in the analysis is the distance to the optimal set.</p>
<p>$$<br>||x_k-x^{opt}||_2^2=||x_{k-1}-tg_{k-1}-x^{opt}||_2^2 \<br>= ||x_{k-1}-x^{opt}||_2^2-2tg_{k-1}^T(x_{k-1}-x^{opt})+t^2||g_{k-1}||_2^2  \<br>\leq ||x_{k-1}-x^{opt}||_2^2-2tg_{k-1}^T(f_{k-1}-f^{opt})+t^2||g_{k-1}||_2^2<br>$$<br>If we define $f_{k}^{best} = \min_{0\leq i &lt; k}f(x_i)$, then<br>$$<br>2(\sum_{i=1}^k t_i)(f_{k}^{best} - f^{opt}) \<br>\leq ||x_0 - x^{opt}||_2^2-||x_k-x^{opt}||_2^2+\sum_{i=1}^k t_i^2||g_{i-1}||<em>2^2 \<br>\leq ||x_0 - x^{opt}||_2^2+\sum\</em>{i=1}^k t_i^2||g_{i-1}||_2^2<br>$$</p>
<ol>
<li><p>for fixed step size $t_i=t$<br> $$</p>
<pre><code>f\_<span class="list">{k}</span>^<span class="list">{best}</span> - f^<span class="list">{opt}</span> \leq \frac<span class="list">{||x\_{0}</span>-x^<span class="list">{opt}</span>||\_2^<span class="number">2</span>}<span class="list">{2kt}</span>+\frac<span class="list">{G^2t}</span><span class="list">{2}</span>
</code></pre><p> $$</p>
<p> Note that</p>
<pre><code><span class="number">1</span>. it does <span class="keyword">not</span> guarantee convergence of <span class="variable">$f_</span>{k}^{best}<span class="variable">$
</span><span class="number">2</span>. <span class="keyword">for</span> large <span class="variable">$k</span><span class="variable">$,</span> <span class="variable">$f</span>\<span class="constant">_{</span>k}^{best}<span class="variable">$ </span>is approximately <span class="variable">$G</span>^<span class="number">2</span>t/<span class="number">2</span><span class="variable">$-</span>suboptimal. 
</code></pre></li>
<li><p>for fixed step length $_i=s/||g_{i-1}||_2$<br> $$</p>
<pre><code>f\_<span class="list">{k}</span>^<span class="list">{best}</span> - f^<span class="list">{opt}</span> \leq \frac<span class="list">{G||x\_{0}</span>-x^<span class="list">{opt}</span>||\_2^<span class="number">2</span>}<span class="list">{2ks}</span>+\frac<span class="list">{Gs}</span><span class="list">{2}</span>
</code></pre><p> $$<br> Note that </p>
<pre><code><span class="number">1</span>. it does <span class="keyword">not</span> guarantee converfence of <span class="variable">$f_</span>{k}^{best}<span class="variable">$
</span><span class="number">2</span>. <span class="keyword">for</span> large <span class="variable">$k</span><span class="variable">$,</span> <span class="variable">$f</span>\<span class="constant">_{</span>k}^{best}<span class="variable">$ </span>is approximately <span class="variable">$Gs</span>/<span class="number">2</span><span class="variable">$-</span>suboptimal. 
</code></pre></li>
<li><p>for diminishing step size $t_k \rightarrow 0$, $\sum_{k=1}^{\infty} t_k = \infty$<br>$$<br>f_{k}^{best} - f^{opt} \leq \frac{G||x_{0}-x^{opt}||_2^2+G^2\sum_{i=1}^k t_i^2}{2\sum_{i=1}^k t_i}<br>$$<br>Because $\frac{\sum_{i=1}^k t_i^2}{\sum_{i=1}^k t_i}\rightarrow 0$, $f_{k}^{best}$ converges to $f^{opt}$.</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/07/29/Subgradient-Method/" data-id="cicp0bv7i0008csffwmgzctij" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/07/29/Subgradient-Method/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Optimization-Method/">Optimization Method</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Gradient-Descent-Method" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/07/24/Gradient-Descent-Method/" class="article-date">
  <time datetime="2015-07-25T02:16:54.000Z" itemprop="datePublished">2015-07-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/24/Gradient-Descent-Method/">Gradient Descent Method</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Gradient method lays the foundation of the optimization algorithm. Thus, we will talk about its basic idea and its convergence in this work.</p>
<h2 id="Definition">Definition</h2><p>In general, we assume that </p>
<ol>
<li>$f(x)$ is convex and differentiable with $dom f = \Re^n$</li>
<li>$\nabla f(x)$ is Lipschitz continous with parameter $L&gt;0$</li>
</ol>
<p>The general form is as follows,<br>$$<br>x_{k+1}=x_{k}-t_k\nabla f(x_k)<br>$$<br>where $\nabla f(x_k)$ is the gradient, $t_k$ is the step size. There are three strategies to determine the step size.</p>
<ol>
<li>Fixed: $t_k$ is constant</li>
<li>exact line search: minimize $f(x-t\nabla f(x))$ over $t$</li>
<li>backtracking line search:</li>
</ol>
<p>The first strategy is the simplest one. Indeed, it is often used, but only in convex optimization, where the behavior of functions is much more predictable than in the general nonlinear case.</p>
<p>The second strategy is completely theoretical. It is never used in practice since even in one-dimensional case we cannot find an exact minimum of a function in finite time.</p>
<p>The third strategy is used in the majority of the practical algorithms. We will talk about this strategy in the future work.</p>
<h2 id="Convergence_of_General_Convex_Function">Convergence of General Convex Function</h2><p>Since $f$ is Lipschitz continous, therefore, for $x_{k+1}=x_{k}-t\nabla f(x)$, we have<br>$$<br>f(x_{k+1})\leq f(x_{k})-\nabla f(x)^T(x_{k+1}-x_{k}) + \frac{L}{2}||x_{k+1}-x_{k}||_2^2 = f(x_k)-t(1-\frac{Lt}{2})||\nabla f(x)||_2^2<br>$$<br>If we set $t\leq 1/L$, then<br>$$<br>f(x_{k+1})\leq f(x_{k})- \frac{t}{2} ||\nabla f(x_k)||_2^2 \\<br>\leq f(x^{opt})+ \nabla f(x_k)^T(x_k-x^{opt})- \frac{t}{2} ||\nabla f(x_k)||_2^2 \\<br>= f(x^{opt})+ \frac{1}{2t} (||x_k-x^{opt}||_2^2-||x_k-x^{opt}||_2^2 + 2t \nabla f(x_k)^T(x_k-x^{opt})-t^2 ||\nabla f(x_k)||_2^2) \\<br>= f(x^{opt})+ \frac{1}{2t} (||x_k-x^{opt}||_2^2 - ||x_k-x^{opt}-t\nabla f(x_k)||_2^2) \\<br>= f(x^{opt})+ \frac{1}{2t} (||x_k-x^{opt}||_2^2 - ||x_{k+1}-x^{opt}||_2^2)<br>$$</p>
<p>Therefore, we have<br>$$<br>\sum_{i=1}^k (f(x_i)-f(x^{opt})) \leq \frac{1}{2t}\sum_{i=1}^k (||x_{i-1}-x^{opt}||_2^2-||x_{i}-x^{opt}||_2^2) \\<br>= \frac{1}{2t} (||x_{0}-x^{opt}||_2^2-||x_{k}-x^{opt}||_2^2) \\<br>\leq \frac{1}{2t} ||x_{0}-x^{opt}||_2^2<br>$$<br>Since $f(x_i)$ is non-increasing, we have<br>$$<br>f(x_k)-f(x^{opt}) \leq \frac{1}{k} \sum_{i=1}^k (f(x_i)-f(x^{opt})) \leq \frac{1}{2kt} ||x_{0}-x^{opt}||_2^2<br>$$</p>
<p>As a result, the number of iterations to reach $f(x_k)-f(x^{opt}) \leq \epsilon$ is $O(1/ \epsilon)$.</p>
<h2 id="Convergence_of_Strongly_Convex_Function">Convergence of Strongly Convex Function</h2><p>For strongly convex function, we have<br>$$<br>f(y)\geq f(x)+\nabla f(x)^T(y-x)+\frac{\mu}{2}||y-x||_2^2<br>$$</p>
<p>If $x_{k+1}=x_{k}-t\nabla f(x)$ and $0&lt; t \leq 2/(\mu+L)$, we have<br>$$<br>||x_{k+1}-x^{opt}||_2^2=||x_k-t \nabla f(x_k)-x^{opt}||_2^2 \\<br>= ||x_{k}-x^{opt}||_2^2 - 2t\nabla f(x_k)^T(x_k-x^{opt})+t^2||\nabla f(x_k)||_2^2 \\<br>\leq (1-t\frac{2mL}{m+L})||x_k-x^{opt}||_2^2+t(t-\frac{2}{m+L})||\nabla f(x_k)||_2^2 \\<br>\leq (1-t\frac{2mL}{m+L})||x_k-x^{opt}||_2^2<br>$$<br>Thus, $||x_k-x^{opt}||_2^2 \leq (1-t\frac{2mL}{m+L})^k ||x_0-x^{opt}||_2^2$ , which implies linear convergence.</p>
<p>Due to the quadratic upper bound of function with Lipschitz continous gradient, we have<br>$$<br>f(x_{k})-f(x^{opt}) \leq \frac{L}{2}||x_{k}-x^{opt}||_2^2 \leq \frac{c^k L}{2}||x_{0}-x^{opt}||_2^2<br>$$<br>As a result, the number of iterations to reach $f(x_k)-f(x^{opt}) \leq \epsilon$ is $O(log(1/ \epsilon))$.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/07/24/Gradient-Descent-Method/" data-id="cicp0bv7l000bcsfflvmxejpj" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/07/24/Gradient-Descent-Method/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Optimization-Method/">Optimization Method</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Convex-Function" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/07/21/Convex-Function/" class="article-date">
  <time datetime="2015-07-21T19:39:44.000Z" itemprop="datePublished">2015-07-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/21/Convex-Function/">Convex Function</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>In this work, we will talk about some properties of convex function, which are usually used in the optimization algorithm. </p>
<h1 id="1-_Convexity">1. Convexity</h1><h2 id="1-1_Definition">1.1 Definition</h2><p>$f$ is convex if $dom f$ is a convex set and Jensen’s inequality holds:<br>$$<br>f(\theta x+(1-\theta) y)\leq \theta f(x)+(1-\theta)f(y)<br>$$<br>for all $x,y\in dom f$ and $\theta \in [0,1]$.</p>
<h2 id="1-2_First-order_condition">1.2 First-order condition</h2><p>For differentiable $f$,<br>$$<br>f(y)\geq f(x)+ \nabla f(x)^T(y-x)<br>$$<br>for all $x,y\in dom f$</p>
<h2 id="1-3_Second-order_condition">1.3 Second-order condition</h2><p>For twice differentiable $f$,<br>$$<br>\nabla^2 f(x) \geq 0<br>$$<br>for all $x \in dom f$</p>
<h1 id="2-_Lipschitz_Continuous_Gradient">2. Lipschitz Continuous Gradient</h1><h2 id="2-1_Definition">2.1 Definition</h2><p>Gradient of $f$ is Lipchitz continous with parameter $L&gt;0$ if<br>$$<br>||\nabla f(x)-\nabla f(y)||_2 \leq L||x-y||_2<br>$$<br>for all $x,y\in dom f$</p>
<ul>
<li>Note that the definition does not assume convexity of $f$</li>
<li>For convex $f$ with $dom f=R^n$, it is equivalent to $\frac{L}{2}x^Tx-f(x)$ is convex.<br>(i.e. if $f$ is twice differentiable and convex, $0 \leq \nabla^2 f(x) \leq LI$ for all $x$)</li>
<li>Note that Lipchitz continuity gives a constraint to $f$, which is that $f$ cannot change dramatically.</li>
</ul>
<h2 id="2-2_Quadatic_upper_bound">2.2 Quadatic upper bound</h2><p>Suppose $\nabla f$ is Lipschitz continous with parameter $L$ and $dom f$ is convex, then<br>$$<br>f(y)\leq f(x) + \nabla f(x)^T(y-x)+\frac{L}{2}||y-x||_2^2<br>$$<br>for all $x,y\in dom f$.</p>
<p>Therefore, for convex $f$ with Lipschitz continous gradient, we have<br>$$<br>f(x) + \nabla f(x)^T(y-x) \leq f(y)\leq f(x) + \nabla f(x)^T(y-x)+\frac{L}{2}||y-x||_2^2<br>$$<br>Just as shown in the following figure.</p>
<h1 id="3-_Strongly_Convex_Function">3. Strongly Convex Function</h1><h2 id="3-1_Definition">3.1 Definition</h2><p>Function $f$ is strongly convext with parameter $\mu&gt;0$ if function<br>$$<br>g(x)=f(x)-\frac{\mu}{2}x^Tx<br>$$<br>is convex.</p>
<h2 id="3-2_First-order_condition">3.2 First-order condition</h2><p>For differentiable $f$,<br>$$<br>f(y)\geq f(x)+\nabla f(x)^T(y-x)+\frac{\mu}{2}||y-x||_2^2<br>$$<br>for all $x,y\in dom f$. It is also called <strong>quadratic lower bound</strong>, just as shown in following figure.</p>
<h2 id="3-3_Second-order_condition">3.3 Second-order condition</h2><p>For twice differentiable $f$,<br>$$<br>\nabla^2 f(x) \geq \mu I<br>$$<br>for all $x \in dom f$.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/07/21/Convex-Function/" data-id="cicp0bv7p000fcsffqkkwg05r" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/07/21/Convex-Function/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Optimization-Method/">Optimization Method</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Density-Estimation" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/07/20/Density-Estimation/" class="article-date">
  <time datetime="2015-07-21T00:21:14.000Z" itemprop="datePublished">2015-07-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/20/Density-Estimation/">Density Estimation</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Introduction">Introduction</h1><p>In <a href="http://yyyouc.github.io/2015/07/18/Bayesian-Decision-Theory/" target="_blank" rel="external">Bayesian Decision Theory</a>, we have talked about how to design a Bayes classifier. In fact, it needs the class-conditional probability density $p(x|w_i)$ and the prior probability $p(w_i)$. But how to get $p(x|w_i)$ and $p(w_i)$? In practice, it is easy to get $p(w_i)$. Therefore, we will mainly talk about how to estimate the class-conditional probability density based on the given dataset.</p>
<p>There are two category method about estimate density. That is <strong>parametric method</strong> and <strong>nonparametric method</strong>. For the parametric method, it assumes that the dataset follows a specific functional form for the distribution with unknown parameters. Then density estimation is transformed to the parameter estimation. For the nonparametric method, the form of the distribution typically depends on the size of the dataset. For example, the histogram method. </p>
<p>In the following, we will talk about the parametric method. The parametric method includes two kinds of method: <strong>maximum likelihood</strong> and <strong>Bayesian method</strong>. </p>
<ul>
<li>Maximum likelihood assumes the samples follows a specific form of distribution whose parameters are <strong>fixed</strong> but unknown. Thus, this method is to estimate the <strong>value of the parameter</strong>. The best estimate of their value is defined to be the one that maximizes the probability of obtaining the samples actually observed.<ul>
<li>Bayesian method views the samples follows a specific form of distribution whose parameters are <strong>random variables</strong> having some known a priori distribution. Thus, this method is to estimate the <strong>distribution of the parameter</strong>, that is the posterior distribution of the parameter.</li>
</ul>
</li>
</ul>
<h2 id="Maximum_Likelihood_Estimation">Maximum Likelihood Estimation</h2><p>As above, we have already know the form of the distribution, but we do not know the value of the parameters. Thus, we need to estimate the value of the parameters. </p>
<p>Denote the parameter as $\theta$, and the $i$-th class (we assume different class has different parameter and they do not affect each other) dataset $D={x_1, x_2,\cdots, x_n}$ drawn independently from the probability density $p(x|\theta)$. Our duty is to estimate the unkown parameter $\theta$ according to dataset $D$.</p>
<p>It is easy to know<br>$$<br>p(D|\theta)=\prod_{i=1}^np(x_i|\theta)<br>$$<br>where $p(D|\theta)$ is called the $likelihood$ of $\theta$ with respect to the set of samples. The maximum likelihood estimate of $\theta$ is the value that maximizes $p(D|\theta)$. Intuitively, <strong>this estimate corresponds to the value of $\theta$ that in some sense best agrees with or supports the actually observed training samples</strong>.</p>
<p>To get the optimal $\theta$, we define the log-likelihood function<br>$$<br>l(\theta)=lnp(D|\theta)=\sum_{i=1}^nlnp(x_i|\theta)<br>$$<br>We can take the derivative of $l(\theta)$ with respect to $\theta$ and set it as zero to get the optimal $\theta$.</p>
<p>This is the basic idea of maximum likelihood estimation.</p>
<h2 id="Bayesian_Estimation">Bayesian Estimation</h2><p>Bayesian estimation also knows the form of the distribution with unkown parameters. But the parameters are random variables, following a prior distribution. Thus, our duty is to estimate such a distribution. That is the posterior distribution of the unkown paramethers.</p>
<p>Denote $p(x|D)$ as the desired class-conditional probability density where $D$ is the training samples and $x$ is the testing sample, then<br>$$<br>p(x|D)=\int p(x,\theta|D)d\theta=\int p(x|\theta)p(\theta|D)d\theta<br>$$<br>where $p(\theta|D)$ is the the posterior density for the unknown parameter, $p(x|\theta)$ is the class-conditional probability density with unkown parameters $\theta$. Therefore, once we know the distribution $p(\theta|D)$, we will know $p(x|\theta)$. At last, we can get the desired class-conditional probability density $p(x|D)$. Thus, <strong>the most important is to estimate $p(\theta|D)$</strong>.</p>
<p>According to Bayes’ formula<br>$$<br>p(\theta|D)=\alpha p(D|\theta)p(\theta)=\alpha \prod_{i=1}^np(x_i|\theta)p(\theta)<br>$$<br>where $p(\theta)$ is the prior probability density and $p(x_i|\theta)$ is the class-conditional probability density with unkown parameters $\theta$.</p>
<p>This is the basic idea of Bayesian estimation.</p>
<p>All in all, the maximum likelihood approach estimates a point in $\theta$ space, the Bayesian approach instead estimates a distribution.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/07/20/Density-Estimation/" data-id="cicp0bv7n000dcsffgdg8yjwn" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/07/20/Density-Estimation/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Bayesian-Decision-Theory" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/07/18/Bayesian-Decision-Theory/" class="article-date">
  <time datetime="2015-07-19T01:38:12.000Z" itemprop="datePublished">2015-07-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/18/Bayesian-Decision-Theory/">Bayesian Decision Theory</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Introduction">Introduction</h2><p>Bayesian decision theory is a fundamental statistical method to the problem of pattern classification. It is to use the probability to perform classification decision. It has two assumptions:</p>
<ul>
<li>the decision problem is posed in probilistic terms;</li>
<li>all the involved probability values are known.</li>
</ul>
<h2 id="Bayes_Formula">Bayes Formula</h2><p>Bayes formula is the basis of the Bayesian decision theory. It is defined as follows:<br>$$<br>P(w_j|x)=\frac{p(x|w_j)P(w_j)}{p(x)}<br>$$<br>where $P(w_j|x)$ is the <strong>posterior probability</strong>, $P(w_j)$ is the <strong>prior probability</strong> and $p(x|w_j)$ is the <strong>conditional probability density</strong>. And $p(x)=\sum_{j=1}^{n}p(x|w_j)P(w_j)$.<br>But what is the meaning of prior probability, posterior probability and the conditional probability density?</p>
<ul>
<li>Prior probability is the assumption that we give to a problem. It may be correct or not. However, we can use conditional probability density to justify it.</li>
<li>Conditional probability density is the likelihood of $w_j$ with respect to $x$. If it is large, it means that $w_j$ is more “likely” to be the true category.</li>
<li>Posterior probability is the justified assumption. </li>
</ul>
<p>In fact, given a data point, we can give an assumption about the category which it belongs to. Such assumption maybe right or not. However, such a data point has some features. Therefore, under such a assumption, we can use these features of the data point to justify whether the assumtion is proper. If so, we will get a large posterior probability. Otherwise, we will get a small one.<br>This is the basic idea of Bayes formula. It can be interpreted as follows:<br>$$<br>posterior = \frac{likelihood\times prior}{evidence}<br>$$<br>This formula shows that by observing the value of $x$ we can convert the prior probability $P(w_j)$to the a  posterior probability $P(w_j|x)$.</p>
<h2 id="Loss_Function">Loss Function</h2><p>Now we can use Bayes formula to give decision about the classification. But how to measure the cost of our decision?</p>
<p>Since $P(w_j|x)$ is the probability that the true state of nature is $w_j$ , the expected loss associated with taking action $\alpha_i$ is<br>$$<br>L(\alpha_i|x)=\sum_{j=1}^{c}I(\alpha_i|w_j)P(w_j|x)<br>$$<br>In decision-theoretic terminology, an expected loss is called a <strong>risk</strong>, and $L(\alpha_i|x)$ is called the <strong>conditional risk</strong>. Whenever we encounter a particular observation $x$, we can minimize our expected loss by selecting the action that minimizes the conditional risk. Since $L(\alpha_i|x)$ is the conditional risk, <strong>overall risk</strong> is given by<br>$$<br>L=\int L(\alpha(x)|x)p(x)dx<br>$$<br>Clearly, if $\alpha(x)$ is chosen such that $L(\alpha(x))$ is as small as possible for every $x$, then the overall risk will be minimized. This justifies the following statement of the Bayes decision rule: To minimize the overall risk, compute the conditional risk<br>$$<br>L(\alpha_i|x)=\sum_{j=1}^{c}I(\alpha_i|w_j)P(w_j|x)<br>$$<br>and select the action $\alpha_i$ for which $L(\alpha_i|x)$ is minimum. The resulting minimum overall risk is called the <strong>Bayes risk</strong>.</p>
<p>Now, let us define a function<br>$$<br>I(\alpha_j|w_i)=\left\{<br>\begin{aligned}<br>0 &amp;&amp; i=j \\<br>1 &amp;&amp; i \neq j \\<br>\end{aligned}<br>\right.<br>$$<br>Then, the conditional risk can be defined as follows.<br>$$<br>L(\alpha_i|x)=\sum_{j=1}^{c}I(\alpha_i|w_j)P(w_j|x) \<br>= \sum_{j\neq i}P(w_j|x) \<br>= 1-P(w_i|x)<br>$$<br>From the definition of the loss function, we can conclude that minimizing loss function $L(\alpha_i|x)$ is to maximize the posterior probability $P(w_j|x)$. In other words, decide $w_i$ if $P(w_i|x)&gt;P(w_j|x)$ for all $j\neq i$</p>
<h2 id="Bayes_Classifier">Bayes Classifier</h2><p>There are many different ways to represent pattern classifiers. One of the most useful is in terms of a set of <strong>discriminant functions</strong> $g_i(x), i = 1\cdots c$. The classifier is said to assign a data point $x$ to class $w_i$ if for all $j\neq i$<br>$$<br>g_i(x)&gt;g_j(x)<br>$$</p>
<p>A Bayes classifier is easily and naturally represented in this way. For the general case with risks, we can let $g_i(x) = -L(\alpha_i|x)$, since the maximum discriminant function will then correspond to the minimum conditional risk. For the minimum-error-rate case, we can simplify things further by taking $g_i(x) = P(w_j|x)$, so that the maximum discriminant function corresponds to the maximum posterior probability.</p>
<p>Clearly, the choice of discriminant functions is not unique. We can always multiply all the discriminant functions by the same positive constant or shift them by the same additive constant without influencing the decision. More generally, if we replace every $g_i(x)$ by $f(g_i(x))$, where $f(.)$ is a monotonically increasing function, the resulting classification is unchanged. This observation can lead to significant analytical and computational simplifications. In particular, for minimum-error-rate classification, any of the following choices gives identical classification results, but some can be<br>much simpler to understand or to compute than others:<br>$$<br>g_i(x)=P(w_i|x) \\<br>g_i(x) = p(x|w_i)P(w_i) \\<br>g_i(x) = lnp(x|w_i)+lnP(w_i)<br>$$</p>
<p>Even though the discriminant functions can be written in a variety of forms, the decision rules are equivalent. The effect of any decision rule is to divide the feature space into $c$ decision regions, $R_1,\cdots, R_c$. If $g_i(x) &gt; g_j(x)$ for all $j\neq i$, then $x$ is in region $R_i$, and the decision rule calls for us to assign $x$ to $w_i$. The regions are separated<br>by decision boundaries, surfaces in feature space where ties occur among the largest discriminant functions.</p>
<h2 id="Naïve_Bayes_Method">Naïve Bayes Method</h2><p>Naïve Bayes is a subset of Bayesian decision theory. It uses the Bayesian decision theory to do classification. Here, Naïve means the features of the data point are independent to each other.</p>
<p>Given a data point $x=(x_1, x_2,\cdots,x_n)$ where $x_i$ is the $i$-th feature of the data point, and given classes $c_1, c_2, \cdots, c_k$. If $P(c_i|x)&gt;P(c_j|x)$ for all $j\neq i$, then data point $x$ belongs to class $c_i$. Specifically,<br>$$<br>P(c_i|x)=\frac{p(x|c_i)P(c_i)}{p(x)}<br>$$<br>Due to the independence of the features, $p(x|c_i)=p(x_1|c_i)p(x_2|c_i)\cdots p(x_n|c_i)$.</p>
<p>This is the basic idea of Naïve Bayes method.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/07/18/Bayesian-Decision-Theory/" data-id="cicp0bv6v0000csff3f88g3ga" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/07/18/Bayesian-Decision-Theory/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Support Vector Machine" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/07/07/Support Vector Machine/" class="article-date">
  <time datetime="2015-07-08T04:09:39.000Z" itemprop="datePublished">2015-07-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/07/Support Vector Machine/">Support Vector Machine</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Introduction">Introduction</h2><p>When it comes to classification methods, there are two categories. The first category is to construct a <strong>discriminant function</strong> for each class, and then classify each sample to the class with the largest value for its discriminant function, such as logistic regression method. The second method is to construct a <strong>separating hyperplane</strong>, such as perceptron method and SVM.</p>
<h2 id="Objective_function">Objective function</h2><p>SVM is to find an optimal separating hyperplane among different classes such that the <strong>margin</strong> is maximized, where margin is the smallest distance between the separating plane and any of the samples. </p>
<p>The objective function is as follows,<br>$$\max_{w,b} margin(w, b) \\<br>s.t. y_i(w^Tx_i+b)&gt;0$$<br>where $margin(w,b)=\min_{i=1,2,..,N}distance(x_i,w,b)$, and $distance(x_i, w, b)=\frac{|w^Tx_i+b|}{||w||}=\frac{y_i(w^Tx_i+b)}{||w||}$. The constraint means that we are only interested in the hyperplane for which all samples are correctly classified.</p>
<p>Due to the linearity of the hyperplane, there exists many representations for the same hyperplane, for example, $(kw)^Tx+kb=0$. To avoid such cases, we scale $w$ and $b$ such that $\min_{i=1,2,..,N} y_i(w^Tx_i+b)=1$. Thus, $margin(w,b)=\frac{1}{||w||}$. Thus, the objective function is as follows.<br>$$ \max_{w,b}\frac{1}{||w||} \\<br>s.t. y_i(w^Tx_i+b)\geq1 $$<br>It is equivalent to the following:<br>$$ \min_{w,b}\frac{1}{2}w^Tw \\<br>s.t. y_i(w^Tx_i+b)\geq1 $$</p>
<h2 id="Optimization_algorithm">Optimization algorithm</h2><p>There are two methods to solve this objective function. The first method is to solve the primal problem directly. The second method is to solve the dual problem.</p>
<h3 id="1-_Primal_problem">1. Primal problem</h3><p>This problem is a quadratic programming (QP) problem. It can be solved directly by many optimization tools. The general form of the QP problem is as follows.<br>$$\min_{u} \frac{1}{2}u^TQu+p^Tu \\<br>s.t.a_i^Tu\geq c_i , i=1,…,m<br>$$<br>The objective function of SVM can be represented as such form, where $u=\left[<br>  \begin{array}{c}<br>    b\\ w<br>  \end{array}<br>\right] $, $Q=\left[<br>  \begin{array}{cc}<br>    0 &amp; 0_d^T \\<br>    0_d &amp; I_d<br>  \end{array}<br>\right] $, $p=0_{d+1}$, $a_i^T=y_i[1,  x_i^T]$,$c_i=1$. For this method, the number of the variables is $d$ (the number of features), and the number of the constraints is $N$ (the number of samples). If $d$ is very large, especially for the kernel SVM, the computation will also be very large. How to address this problem? We can solve the dual problem rather than the primal problem.</p>
<h3 id="2-_Dual_problem">2. Dual problem</h3><h4 id="2-1_Duality">2.1 Duality</h4><p>At first, we will talk about some basic knowledge about the dual problem. We consider a standard optimization problem:<br>$$<br>\min f_0(x)  \\<br>s.t. f_i(x) \leq 0, i=1,…,m \\<br>h_i(x) = 0, i=1,…,p<br>$$<br>This is a constrained optimization problem. Ususally it is more difficult to solve than the unconstrained optimization problem. Can we transform it to an unconstrained one? Of course, we define a Lagrangian function as follows:<br>$$L(x,\lambda, v)=f_0(x)+\sum_{i=1}^m\lambda_i f_i(x)+\sum_{i=1}^pv_ih_i(x)$$<br>where $\lambda_i$ and $v_i$ is the Lagrangian multiplier. Note that we put the constraint into the objective function so that it becomes an uncontrained problem. However, are they equivalent?<br>Consider the following function:<br>\begin{equation}<br>\theta_p(x)=\max_{\lambda_i,v_i: \lambda_i\geq 0} L(x, \lambda, v)<br>\end{equation}<br>If some constraint are violated, such as $f_i(x)&gt;0$ or $h_i(x)\neq0$, we can adjust $\lambda_i$ and $v_i$ such that $\theta_p(x)$ approaches to infinity. If all the constraints are satisifed, it is easy to know that $\lambda_i$ should be equal to 0, and then $\theta_p(x)$ is equal to $f_0(x)$ exactly. Thus, we can minimize $\theta_p(x)$ to enforce the constraint to be satisfied, that is<br>\begin{equation}<br>\min_{x}\theta_p(x)=\min_{x} \max_{\lambda_i,v_i: \lambda_i\geq 0} L(x, \lambda, v)<br>\end{equation}<br>then it will be equivalent the standard form. This is the primal problem, in the following we will derive the dual problem. Note that for any $\lambda’$ and $v’$, we have $$\min_{x} \max_{\lambda_i,v_i: \lambda_i\geq 0} L(x, \lambda, v) \geq \min_{x} L(x, \lambda’, v’)$$ (because max $\geq$ any), and then $$\min_{x} \max_{\lambda_i,v_i: \lambda_i\geq 0} L(x, \lambda, v) \geq \max_{\lambda_i’,v_i’: \lambda_i’\geq 0}\min_{x} L(x, \lambda’, v’)$$ (because best is one of any).<br>The right side is the dual problem, and $\min_{x} L(x, \lambda, v)$ is the dual function. Note that the dual problem gives a lower bound to the primal problem. </p>
<p>When the solution $x^{<em>}$, $\lambda^{</em>}$ and $v^{*}$ satisfy the KKT conditions, they are the solution of both primal and dual problems.</p>
<h4 id="2-2_Dual_SVM">2.2 Dual SVM</h4><p>Based on the above foundation, the dual SVM is as follows<br>$$\max_{\alpha_i\geq 0}{\min_{b,w}\frac{1}{2}w^Tw+\sum_{i=1}^{N}\alpha_i(1-y_i(w^Tx_i+b))}$$</p>
<p>At first, we solve the inner problem<br> $$\min_{b,w}\frac{1}{2}w^Tw+\sum_{i=1}^{N}\alpha_i(1-y_i(w^Tx_i+b))$$<br> This is an unconstrained problem. It is easy to solve by setting the direvative with respect to $w$ and $b$ as zero. We can get<br> $$<br> \sum_{i=1}^{N}\alpha_iy_i=0 \\<br> \sum_{i=1}^{N}\alpha_iy_ix_i=w<br> $$<br> Then,<br>$$<br>\frac{1}{2}w^Tw+\sum_{i=1}^{N}\alpha_i(1-y_i(w^Tx_i+b)) \\<br>=\frac{1}{2}w^T\sum_{i=1}^{N}\alpha_iy_ix_i+\sum_{i=1}^{N}\alpha_i-w^T\sum_{i=1}^N\alpha_iy_ix_i-b\sum_{i=1}^N\alpha_iy_i \\<br>=\sum_{i=1}^{N}\alpha_i-\frac{1}{2}w^T\sum_{i=1}^{N}\alpha_iy_ix_i \\<br>= \sum_{i=1}^{N}\alpha_i-\frac{1}{2}(\sum_{i=1}^{N}\alpha_iy_ix_i)^T\sum_{i=1}^{N}\alpha_iy_ix_i \\<br>= \sum_{i=1}^{N}\alpha_i-\frac{1}{2}\sum_{i,j=1}^{N}\alpha_i\alpha_jy_iy_jx_i^Tx_j<br>$$<br>Now we have the dual problem as follows.<br>$$<br>\min \frac{1}{2}\sum_{i=1}^{N}\sum_{j=1}^{N}\alpha_i\alpha_jy_iy_jx_i^Tx_j-\sum_{i=1}^{N}\alpha_i \\<br>s.t. \alpha_i \geq 0, i=1,…,N \\<br> \sum_{i=1}^{N}\alpha_iy_i=0<br>$$<br>This is a QP with $N$ variables and $N+1$ constraints. Therefore, it can be easily solved by optimization tools. Note that when we solve this QP, the matrix $Q$ consists of $q_{ij}=y_iy_jx_i^Tx_j$ usually is dense. Thus, it needs large storage.</p>
<p>After we got the solution of the dual problem, how can we get the primal solution $w$ and $b$? Note that $w=\sum_{i=1}^{N}\alpha_iy_ix_i$. Whats more, according to the KKT dual complementary conditions,$\alpha_i(1-y_i(w^Tx_i+b))=0$, if $\alpha_i&gt;0$, $1-y_i(w^Tx_i+b)=0$, that is $b=y_i-w^Tx_i$. Note that $\alpha_i&gt;0$ means $y_i(w^Tx_i+b)=1$, thus this point locates on the boundary. Such points are called <strong>support vector</strong>. </p>
<p>After obtainning the optimal $w$ and $b$ from the trainning data, we can classify the test data by the following formula.<br>$$<br>w^Tx+b=(\sum_{i=1}^N\alpha_iy_ix_i)^Tx+b=\sum_{i=1}^N\alpha_iy_i x_i^Tx+b<br>$$<br>Note that we only need to calculate the inner product between the testing data and the support vector (corresponds to $\alpha_i&gt;0$) rather than the whole training data, thus it is efficient.</p>
<h2 id="Soft-Margin_SVM">Soft-Margin SVM</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/07/07/Support Vector Machine/" data-id="cicp0bv7g0006csff0vycjw2l" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/07/07/Support Vector Machine/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/05/17/hello-world/" class="article-date">
  <time datetime="2015-05-18T01:29:05.546Z" itemprop="datePublished">2015-05-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/05/17/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="http://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="http://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="http://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick_Start">Quick Start</h2><h3 id="Create_a_new_post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run_server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate_static_files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy_to_remote_sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="http://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/05/17/hello-world/" data-id="cicp0bv7d0003csff4tz7zoqi" class="article-share-link">Share</a>
      
        <a href="http://yoursite.com/2015/05/17/hello-world/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hexo/">Hexo</a></li></ul>

    </footer>
  </div>
  
</article>


  
  
</section>
        
          <aside id="sidebar">
  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/">Hexo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Optimization-Method/">Optimization Method</a><span class="tag-list-count">3</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a><a href="/tags/Machine-Learning/" style="font-size: 20px;">Machine Learning</a><a href="/tags/Optimization-Method/" style="font-size: 20px;">Optimization Method</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/07/">July 2015</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">May 2015</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2015/07/29/Subgradient-Method/">Subgradient Method</a>
          </li>
        
          <li>
            <a href="/2015/07/24/Gradient-Descent-Method/">Gradient Descent Method</a>
          </li>
        
          <li>
            <a href="/2015/07/21/Convex-Function/">Convex Function</a>
          </li>
        
          <li>
            <a href="/2015/07/20/Density-Estimation/">Density Estimation</a>
          </li>
        
          <li>
            <a href="/2015/07/18/Bayesian-Decision-Theory/">Bayesian Decision Theory</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
			
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 YYY OUC<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    
<script>
  var disqus_shortname = 'yyyouc';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>


<script type="text/x-mathjax-config"> 
MathJax.Hub.Config({ 
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} 
}); 
</script>
<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	



  </div>
</body>
</html>